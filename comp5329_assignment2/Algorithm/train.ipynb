{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A5jh6omK3pvz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "gNWHUqqdWeg7",
    "outputId": "4bad0e03-d9a5-4376-c91d-ae84816ae3c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqCLqdSbD97F"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/My Drive/comp5329assignment2/\"\n",
    "\n",
    "tar = tarfile.open(path+\"train.tar.gz\")\n",
    "names = tar.getnames()\n",
    "for name in names:\n",
    "    tar.extract(name, path = \"/content/train_data/\")\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgARed2lgSOH"
   },
   "outputs": [],
   "source": [
    "label_file = np.loadtxt(path+\"train.txt\", dtype=bytes)\n",
    "np.random.shuffle(label_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5z0SuepDlKAU"
   },
   "outputs": [],
   "source": [
    "label_0 = label_file[:,0].astype(str)\n",
    "label_1 = label_file[:,1].astype(str)\n",
    "\n",
    "new_arr = np.append(label_0.reshape(-1,1),label_1.reshape(-1,1), axis = 1)\n",
    "df = pd.DataFrame(new_arr,columns = ['Filenames', 'labels'])\n",
    "df[\"labels\"] = df[\"labels\"].apply(lambda x: list(map(int, x.split(\",\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Nc7omqvgfGhq",
    "outputId": "4b5956d0-a14a-406c-fa31-88208dcac27f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25540 images belonging to 20 classes.\n",
      "Found 6385 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "batch_size = 32\n",
    "train_dir = \"/content/train_data/train2014\"\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    zca_epsilon=1e-06,  \n",
    "    rotation_range=15,  \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,  \n",
    "    zoom_range=0.05, \n",
    "    fill_mode='nearest',\n",
    "    cval=0., \n",
    "    horizontal_flip=True,  \n",
    "    vertical_flip=False\n",
    "    )\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = df[0:25540],\n",
    "    directory = train_dir,\n",
    "    x_col = 'Filenames',\n",
    "    y_col = 'labels',\n",
    "    batch_size = batch_size,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (image_size, image_size)\n",
    "    )\n",
    "\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = df[25540:],\n",
    "    directory = train_dir,\n",
    "    x_col = 'Filenames',\n",
    "    y_col = 'labels',\n",
    "    batch_size = batch_size,\n",
    "    seed = 42,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (image_size, image_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "8wcKZ2KGjBPI",
    "outputId": "3ef3e951-229a-42ed-8514-d531f390e52c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# base_model = keras.applications.vgg16.VGG16(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "# base_model = keras.applications.resnet50.ResNet50(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "# base_model = keras.applications.xception.Xception(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "# base_model = keras.applications.densenet.DenseNet121(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "# base_model = keras.applications.densenet.DenseNet169(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "base_model = keras.applications.densenet.DenseNet201(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "base_model.trainable = False\n",
    "# base_model.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "ICssO_xxj_bO",
    "outputId": "7cfdaddc-7bfb-4e4c-d472-cbe20dd60ed4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(20, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "F-kmVB73kN0m",
    "outputId": "7e923b7f-680f-44d1-c0d6-601ee1466885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 7, 7, 1920)        18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               983552    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 19,582,548\n",
      "Trainable params: 1,258,516\n",
      "Non-trainable params: 18,324,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lapu3NCCfip6"
   },
   "outputs": [],
   "source": [
    "def metric(y_true,y_pred):\n",
    "\n",
    "    return tf.math.reduce_max(\n",
    "            tf.multiply(y_true, K.round(y_pred)),\n",
    "            axis=1,\n",
    "            keepdims=None,\n",
    "            name=None,\n",
    "            reduction_indices=None,\n",
    "            keep_dims=None\n",
    "            )\n",
    "# https://github.com/mkocabas/focal-loss-keras/blob/master/focal_loss.py\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',loss=\"binary_crossentropy\",metrics=[metric] )\n",
    "# model.compile(optimizer = 'adam',loss=focal_loss(),metrics=[metric] )\n",
    "\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "validation_steps = val_generator.n // batch_size\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs = 20,steps_per_epoch = steps_per_epoch,validation_data = val_generator, validation_steps= validation_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NxMZyZVviEJS",
    "outputId": "b51e5085-29f9-43be-ca20-35f2dc4a8b50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6385 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = df[25540:],\n",
    "    directory = train_dir,\n",
    "    x_col = 'Filenames',\n",
    "    has_ext = True,\n",
    "    y_col = 'labels',\n",
    "#     subset = \"validation\",\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (image_size, image_size)\n",
    "    )\n",
    "test_generator.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rM7GrwXx1iPb"
   },
   "outputs": [],
   "source": [
    "y_pre_cat = model.predict_generator( test_generator )\n",
    "\n",
    "y_pred = np.argmax(y_pre_cat, axis=1)\n",
    "y_true = df[25540:][\"labels\"].values\n",
    "\n",
    "\n",
    "assert(y_true.shape[0] == y_pred.shape[0])\n",
    "count = 0\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_pred[i] in y_true[i]:\n",
    "        count += 1\n",
    "print(count/y_pred.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bzd1TRwOA0xV"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1v20CxrSOHn1"
   },
   "source": [
    "# Use all data, re-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6Z-IaAI6GVFn",
    "outputId": "6bcd326e-85a3-4227-93d7-168e8c1c7f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31925 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    zca_epsilon=1e-06,  \n",
    "    rotation_range=15,  \n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,  \n",
    "    zoom_range=0.05, \n",
    "    fill_mode='nearest',\n",
    "    cval=0., \n",
    "    horizontal_flip=True,  \n",
    "    vertical_flip=False\n",
    "    )\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    directory = train_dir,\n",
    "    x_col = 'Filenames',\n",
    "    y_col = 'labels',\n",
    "    batch_size = batch_size,\n",
    "    seed = 42,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (image_size, image_size)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "id": "jXzhlZRYnU2l",
    "outputId": "c4ed7a93-eeaf-4625-a550-8031ff6e56a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "998/998 [==============================] - 544s 545ms/step - loss: 0.1492\n",
      "Epoch 2/20\n",
      "998/998 [==============================] - 497s 498ms/step - loss: 0.1231\n",
      "Epoch 3/20\n",
      "998/998 [==============================] - 502s 503ms/step - loss: 0.1187\n",
      "Epoch 4/20\n",
      "998/998 [==============================] - 498s 499ms/step - loss: 0.1159\n",
      "Epoch 5/20\n",
      "998/998 [==============================] - 502s 503ms/step - loss: 0.1141\n",
      "Epoch 6/20\n",
      "998/998 [==============================] - 503s 504ms/step - loss: 0.1130\n",
      "Epoch 7/20\n",
      "998/998 [==============================] - 497s 498ms/step - loss: 0.1112\n",
      "Epoch 8/20\n",
      "998/998 [==============================] - 499s 500ms/step - loss: 0.1106\n",
      "Epoch 9/20\n",
      "998/998 [==============================] - 484s 485ms/step - loss: 0.1082\n",
      "Epoch 10/20\n",
      "998/998 [==============================] - 484s 485ms/step - loss: 0.1075\n",
      "Epoch 11/20\n",
      "998/998 [==============================] - 485s 486ms/step - loss: 0.1073\n",
      "Epoch 12/20\n",
      "998/998 [==============================] - 485s 486ms/step - loss: 0.1061\n",
      "Epoch 13/20\n",
      "998/998 [==============================] - 482s 483ms/step - loss: 0.1055\n",
      "Epoch 14/20\n",
      "998/998 [==============================] - 484s 485ms/step - loss: 0.1041\n",
      "Epoch 15/20\n",
      "998/998 [==============================] - 482s 483ms/step - loss: 0.1038\n",
      "Epoch 16/20\n",
      "998/998 [==============================] - 483s 483ms/step - loss: 0.1028\n",
      "Epoch 17/20\n",
      "998/998 [==============================] - 484s 485ms/step - loss: 0.1022\n",
      "Epoch 18/20\n",
      "998/998 [==============================] - 482s 483ms/step - loss: 0.1018\n",
      "Epoch 19/20\n",
      "998/998 [==============================] - 483s 484ms/step - loss: 0.1012\n",
      "Epoch 20/20\n",
      "998/998 [==============================] - 484s 485ms/step - loss: 0.1005\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.densenet.DenseNet201(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(512),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(20, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam',loss=\"binary_crossentropy\")\n",
    "steps_per_epoch = train_generator.n // batch_size\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs = 20,steps_per_epoch = steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcJrp8KoJFgm"
   },
   "outputs": [],
   "source": [
    "model.save(path+\"my_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qc_2QQ-qGo8z"
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open(path+\"test.tar.gz\")\n",
    "\n",
    "names = tar.getnames()\n",
    "for name in names:\n",
    "    tar.extract(name, path = \"/content/test_data/\")\n",
    "tar.close()\n",
    "names = names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gIunmi_5G5pw",
    "outputId": "c39bf1ed-39e7-48d4-f137-ab64b01537e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15516"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files_name = []\n",
    "for n in names:\n",
    "    test_files_name.append(n[8:])\n",
    "    \n",
    "# 15516\n",
    "len(test_files_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZKKRDtVTWmN"
   },
   "outputs": [],
   "source": [
    "assert(len(test_files_name) == 15516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9TVtYN22HwRo"
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_files_name,columns = ['test_filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ieDkcMzXIiE2",
    "outputId": "e43e453f-f76f-450f-a74a-fff8dab8cc56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15516 images.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "test_dir = \"/content/test_data/val2014\"\n",
    "test_generator = validation_datagen.flow_from_dataframe(\n",
    "    dataframe = test_df,\n",
    "    directory = test_dir,\n",
    "    x_col = 'test_filenames',\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    shuffle = False,\n",
    "    class_mode = None,\n",
    "    target_size = (image_size, image_size)\n",
    "    )\n",
    "test_generator.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3n4Iw3hJGF_"
   },
   "outputs": [],
   "source": [
    "y_pre_cat = model.predict_generator( test_generator )\n",
    "\n",
    "y_pred = np.argmax(y_pre_cat, axis=1)\n",
    "\n",
    "# model.predict_generator( test_generator )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "kQwkCv7mwlCP",
    "outputId": "496d0d45-c816-4f72-9c95-14e4099b140b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15516,)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-AjK3f5XtJ2"
   },
   "source": [
    "# Save predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bWg-peReWAVV"
   },
   "outputs": [],
   "source": [
    "assert(y_pred.shape[0] == 15516)\n",
    "\n",
    "test_file = np.array(test_files_name)\n",
    "res = np.append(test_file.reshape(-1,1),y_pred.reshape(-1,1), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-c8oM0X6bTie"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(res).to_csv(path+\"Prediected_labels.txt\", header=None, index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFphicU3XokT"
   },
   "source": [
    "# To load predicted test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jem6Db9mc4oG"
   },
   "outputs": [],
   "source": [
    "predicted_test_data = pd.read_csv(path+'Prediected_labels.txt', sep=\"\\t\", header=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
