{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import sys; \n",
    "sys.path.append('/path.to.parent.dir') \n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "# a = \"~\"+cwd+'/images_training.h5'\n",
    "# a\n",
    "# load data\n",
    "with h5py.File(\"../Input/images_training.h5\",'r') as H:\n",
    "    data = np.copy(H['data']) \n",
    "with h5py.File(\"../Input/labels_training.h5\",'r') as H:\n",
    "    label = np.copy(H['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the data from (30000,28,28) to (30000, 784)\n",
    "m=data.shape[1]*data.shape[2]\n",
    "data1 = data.reshape(30000,m)\n",
    "del data\n",
    "# data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the amount of different labels\n",
    "target = set()\n",
    "for i in label:\n",
    "    target.add(i)\n",
    "d = len(list(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ovr, e.g. label \"1\" vs. not label \"1\" \n",
    "# make 10 different label set, and combine them together\n",
    "label1 = np.array([])\n",
    "for i in range(d):\n",
    "    label_tmp=np.copy(label)\n",
    "    for tmp in range(len(label_tmp)):\n",
    "        if label_tmp[tmp] != i:\n",
    "            label_tmp[tmp] = 0\n",
    "        else:\n",
    "            label_tmp[tmp] = 1\n",
    "    label_tmp= label_tmp.reshape(-1,1)\n",
    "    if i == 0:\n",
    "        label1 = np.copy(label_tmp)\n",
    "    else:\n",
    "        label1 = np.append(label1, label_tmp, axis=1)\n",
    "del label_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min max scaler \n",
    "mindata = data1.min(axis=0)\n",
    "maxdata = data1.max(axis=0)\n",
    "data_normalize = (data1-mindata) / (maxdata - mindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA class\n",
    "class PCA():\n",
    "    # calculate the covariance matrix, \n",
    "    def covariance_matrix(self, X, Y=None):\n",
    "        # m is number of data, which is also the number of rows.\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        #each element in the row subtracts the mean of this row, \n",
    "        #it makes it's easier to calculate the covariance. \n",
    "        X = X - np.mean(X, axis=0)\n",
    "        Y = X if Y == None else Y - np.mean(Y, axis=0)\n",
    "        return 1 / m * np.matmul(X.T, Y)\n",
    "\n",
    "    def transform(self, X, new_dimension):\n",
    "        # new_dimension is the new dimension, which is the number of cloumns. \n",
    "        covariance_matrix = self.covariance_matrix(X)\n",
    "        # calculate the eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "        # Arrange the feature vectors into a matrix ac-cording  to  the  \n",
    "        # corresponding  feature  valuefrom  top  to  bottom,  \n",
    "        # taking  the  first  k(new_dimension) rows\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        eigenvectors = eigenvectors[:, :new_dimension]\n",
    "\n",
    "        # eigenvectors is the matrix to reduce dimension \n",
    "        return np.matmul(X, eigenvectors), eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pca to training data\n",
    "data_normalize, eigenvectors = PCA().transform(data_normalize, 260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 260)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 260)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 261)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to each training sample for w0 in weight \n",
    "forw0 = np.full((data_normalize.shape[0], 1), 1)\n",
    "data_normalize = np.append(data_normalize, forw0, axis=1)\n",
    "data_normalize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function for logistic regression\n",
    "def f(w, data,label):\n",
    "    data = np.matrix(data)\n",
    "    label = np.matrix(label)\n",
    "    w = np.matrix(w)\n",
    "    \n",
    "    w=w.reshape(-1,1)\n",
    "    \n",
    "    z = data.dot(w)\n",
    "    return np.sum(np.log(1+np.exp(z))- np.multiply(label,z) ,axis=0)\n",
    "\n",
    "# the gradient function for the loss function\n",
    "def jacobian(weights,inputs, targets ):\n",
    "#     (weights, inputs, targets)\n",
    "    inputs = np.matrix(inputs)\n",
    "    targets = np.matrix(targets)\n",
    "    weights = np.matrix(weights)\n",
    "    weights=weights.reshape(-1,1)\n",
    "    \n",
    "    z = np.dot(inputs, weights)\n",
    "    exp_z = np.exp(z)\n",
    "#     print(exp_z)\n",
    "    temp = -exp_z/(1 + exp_z) + targets\n",
    "    dloss = -np.sum(np.multiply(temp,inputs), axis=0)\n",
    "    dloss = dloss.flatten()\n",
    "    return dloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "finish training\n"
     ]
    }
   ],
   "source": [
    "print(\"start training\")\n",
    "from scipy.optimize import minimize\n",
    "import numpy.linalg as lng\n",
    "import time\n",
    "weights = np.array([])\n",
    "t1 = time.time()\n",
    "# for each label, train a logistic regression model\n",
    "for i in range(d):\n",
    "    # initialize weight\n",
    "    weight = np.full((data_normalize.shape[1], 1), 0.1)\n",
    "    current_label = (label1[:,i]).reshape(-1,1)\n",
    "    #use scipy.optimize.minimize to get weight\n",
    "    p = {\"maxiter\":400}\n",
    "    result = minimize(f, weight,\n",
    "                      jac =jacobian,method=\"L-BFGS-B\",tol=1e-4,\n",
    "                      args=(data_normalize,current_label), options = p) \n",
    "    weight = (result.x).reshape(-1,1)\n",
    "    # combine weight together\n",
    "    if i == 0:\n",
    "        weights = weight\n",
    "    else:\n",
    "        weights = np.append(weights, weight, axis = 1)\n",
    "t2 = time.time() \n",
    "print(\"finish training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.0595440864563 seconds\n"
     ]
    }
   ],
   "source": [
    "# print training time\n",
    "print(str(t2-t1),\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '../labels_testing_2000.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b6ce684534c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Input/images_testing.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdata_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../labels_testing_2000.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabel_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '../labels_testing_2000.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "#load test data\n",
    "with h5py.File('../Input/images_testing.h5','r') as H:\n",
    "    data_testing = np.copy(H['data']) \n",
    "with h5py.File('../labels_testing_2000.h5','r') as H:\n",
    "    label_testing = np.copy(H['label'])\n",
    "\n",
    "# reshape the data\n",
    "data_testing = data_testing.reshape(5000,-1)\n",
    "# do normalizing\n",
    "data_testing = (data_testing-mindata) / (maxdata - mindata)\n",
    "# PCA\n",
    "data_testing = np.matmul(data_testing, eigenvectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1 to each test data\n",
    "forw0 = np.full((data_testing.shape[0], 1), 1)\n",
    "data_testing = np.append(data_testing, forw0[0:5000], axis=1)\n",
    "# do prediction\n",
    "calculation = data_testing.dot(weights)\n",
    "\n",
    "result = np.argmax(calculation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pylab as plt\n",
    "to_submit = result[2000:5001]\n",
    "result = result[0:2000]\n",
    "\n",
    "confusion_matrix(label_testing, result)\n",
    "cm = confusion_matrix(label_testing, result, labels=[0,1,2,3,4,5,6,7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    else:\n",
    "        pass\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(label_testing, result)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1,2,3,4,5,6,7,8,9],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = [] \n",
    "for idx in range(10):\n",
    "    diag = cm[idx][idx]\n",
    "    precision = round(diag/np.sum(cm[:,idx]),3)\n",
    "    recall = round(diag/np.sum(cm[idx]),3)\n",
    "    f1 = round((2*recall*precision)/(recall+precision),3)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)\n",
    "    print(\"for label\",idx, \" precision is \",precision,\" recall is \",recall,\" f1 is \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"for label 0 to 9\")\n",
    "print(\"precisions: \",precisions)\n",
    "print(\"recalls: \", recalls)\n",
    "print(\"f1s: \",f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy is \",accuracy_score(label_testing, result)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h5py.File('../Output/to_submit.h5', 'w')\n",
    "dset = h.create_dataset('label', data=to_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('to_submit.h5','r') as H:\n",
    "#     label_testing111 = np.copy(H['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
