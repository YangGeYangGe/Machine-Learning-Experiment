{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5328 Assignment 2 Loss function correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#------------------------------#\n",
    "# loaddta(): load data\n",
    "# standard(): normalise data\n",
    "#------------------------------#\n",
    "\n",
    "def loaddata():\n",
    "    dataset_mnist = np.load('mnist_dataset.npz')\n",
    "    dataset_cifar = np.load('cifar_dataset.npz')\n",
    "\n",
    "    Xtr_mnist = dataset_mnist['Xtr']\n",
    "    Str_mnist = dataset_mnist['Str']\n",
    "    Xts_mnist = dataset_mnist['Xts']\n",
    "    Yts_mnist = dataset_mnist['Yts']\n",
    "\n",
    "    Xtr_cifar = dataset_cifar['Xtr']\n",
    "    Str_cifar = dataset_cifar['Str']\n",
    "    Xts_cifar = dataset_cifar['Xts']\n",
    "    Yts_cifar = dataset_cifar['Yts']\n",
    "\n",
    "    return Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar\n",
    "\n",
    "\n",
    "def standard(x_train, x_test):\n",
    "    '''\n",
    "    Note:\n",
    "         Use the std and mean from the training data and implement\n",
    "         it to the validation data and test data\n",
    "    RETRUN:\n",
    "        Flattened and standard(Z-score normalization) training data\n",
    "        The features size is 3072 or 784\n",
    "    '''\n",
    "    std = np.std(x_train, keepdims=True)\n",
    "    mean = np.mean(x_train, keepdims=True)\n",
    "    x_train = (x_train-mean)/std\n",
    "    x_test = (x_test-mean)/std\n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "def min_max_nor(x_train, x_test, TYPE='mnist'):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    # if TYPE == 'mnist':\n",
    "    #     return x_train.reshape(28, 28), x_test.reshape(28, 28)\n",
    "    # else:\n",
    "    #     return x_train.reshape(32, 32, 3), x_test(32, 32, 3)\n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "#============#\n",
    "# split_data\n",
    "#============#\n",
    "\n",
    "def split_data(x_train, y_train, part=0.8):\n",
    "    '''\n",
    "    Shuffle then data and then split the data accroding to the part parameters\n",
    "    '''\n",
    "    # shuffle the data\n",
    "    order = np.argsort(np.random.random(y_train.shape[0]))\n",
    "    x_train = x_train[order]\n",
    "    y_train = y_train[order]\n",
    "\n",
    "    # split data to train data and validation data\n",
    "    num_total_train = len(x_train)\n",
    "    split_index = int(num_total_train*part)\n",
    "\n",
    "    # index data\n",
    "    x_vali = x_train[split_index:]\n",
    "    y_vali = y_train[split_index:]\n",
    "\n",
    "    x_train = x_train[:split_index]\n",
    "    y_train = y_train[:split_index]\n",
    "\n",
    "    return x_train, y_train, x_vali, y_vali\n",
    "\n",
    "\n",
    "#==================#\n",
    "# One-hot embedding\n",
    "#==================#\n",
    "\n",
    "def one_hot_coding(y_train, y_test):\n",
    "    '''\n",
    "    Encode label to one-hot catogory\n",
    "    '''\n",
    "    y_train = to_categorical(y_train, num_classes=2)\n",
    "    y_test = to_categorical(y_test, num_classes=2)\n",
    "    return y_train, y_test\n",
    "\n",
    "def compute_acc(y_ture, y_pred):\n",
    "    acc = np.sum(y_ture == np.argmax(y_pred, axis=1))/len(y_ture)\n",
    "    return round(acc, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model and loss function correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout,BatchNormalization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# loss correction\n",
    "def robust(name, T):\n",
    "\n",
    "    if name == 'backward':\n",
    "        T_inv = K.constant(np.linalg.inv(T))\n",
    "\n",
    "        def loss(y_true, y_pred):\n",
    "            y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "            y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
    "            return -K.sum(K.dot(y_true, T_inv) * K.log(y_pred), axis=-1)\n",
    "\n",
    "    elif name == 'forward':\n",
    "        T = K.constant(T)\n",
    "\n",
    "        def loss(y_true, y_pred):\n",
    "            y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "            y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
    "            \n",
    "            return -K.sum(y_true * K.log(K.dot(y_pred, T)), axis=-1)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Compute T fucntion\n",
    "def compute_T(y_predict):\n",
    "    '''\n",
    "    model: trained on label noise data\n",
    "    y_predict: (m,2)\n",
    "    '''\n",
    "    T = np.zeros((2, 2))\n",
    "    index = int(y_predict.shape[0]*0.90)\n",
    "    x_max_0 = y_predict[y_predict[:,0].argsort()][index]\n",
    "    x_max_1 = y_predict[y_predict[:,1].argsort()][index]\n",
    "    T[0][0] = x_max_0[0]\n",
    "    T[0][1] = x_max_0[1]\n",
    "    T[1][0] = x_max_1[0]\n",
    "    T[1][1] = x_max_1[1]\n",
    "    return T\n",
    "\n",
    "\n",
    "# model\n",
    "def train_cnn_model(x_train, y_train, x_vali, y_vali, TYPE='with_noise',\n",
    "                    lr=0.0001, decay=0.000001, batchsize=256, epochs=1,T=None,loss_name=None):\n",
    "    '''\n",
    "    x_train: original data\n",
    "    y_train: one-hot encoding\n",
    "\n",
    "    Traning resnet model on label nosie data\n",
    "    Usesd for estimate the T\n",
    "    '''\n",
    "    # data is mnist\n",
    "    if x_train.shape[3] == 1:\n",
    "        model = Sequential([\n",
    "            Conv2D(64, (2, 2), use_bias=True, padding='same', activation='relu',input_shape=(28,28,1)),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(64, (2, 2), use_bias=True, padding='same', activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(1000, activation='relu', use_bias=True),\n",
    "            Dense(500, activation='relu', use_bias=True),\n",
    "            Dense(2, activation=tf.nn.softmax)\n",
    "        ])\n",
    "        \n",
    "    # data is cifar\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Conv2D(64, (2, 2), use_bias=True, padding='same', activation='relu',input_shape=(32,32,3)),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(64, (2, 2), use_bias=True, padding='same', activation='relu'),\n",
    "            Flatten(),\n",
    "            Dense(1000, activation='relu', use_bias=True),\n",
    "            Dense(500, activation='relu', use_bias=True),\n",
    "            Dense(2, activation=tf.nn.softmax)\n",
    "        ])\n",
    "\n",
    "\n",
    "    datagen = ImageDataGenerator(featurewise_std_normalization=False)\n",
    "    datagen.fit(x_train)\n",
    "    adm = optimizers.Adam(lr=lr, decay=decay)\n",
    "    if TYPE == 'with_noise':\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=adm,\n",
    "                      metrics=['accuracy'])\n",
    "    elif TYPE == 'without_noise':\n",
    "        model.compile(loss=robust(loss_name, T),\n",
    "                      optimizer=adm,\n",
    "                      metrics=['accuracy'])\n",
    "    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batchsize),\n",
    "                                  steps_per_epoch=len(x_train) / batchsize, epochs=epochs, validation_data=(x_vali, y_vali))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark function for SVM, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------#\n",
    "# SVM benchmark\n",
    "#--------------#\n",
    "def SVM_benchmark(x_train, y_train, x_test, y_test, C=1):\n",
    "    '''\n",
    "    Do cross validation interation times \n",
    "    Data: flatten and normalized \n",
    "    Return:\n",
    "        Accuracy mean and std\n",
    "    '''\n",
    "    interation = 10\n",
    "    train_scores = np.zeros(interation)\n",
    "    vali_scores = np.zeros(interation)\n",
    "    test_scores = np.zeros(interation)\n",
    "    for i in range(interation):\n",
    "        x_train_, y_train_, x_vali_, y_vali_ = split_data(x_train, y_train)\n",
    "        clf = svm.SVC(C=C, kernel='poly').fit(x_train_, y_train_)\n",
    "        train_scores[i] = clf.score(x_train_, y_train_)\n",
    "        vali_scores[i] = clf.score(x_vali_, y_vali_)\n",
    "        test_scores[i] = clf.score(x_test, y_test)\n",
    "    return train_scores.mean(), train_scores.std() * 2, vali_scores.mean(), vali_scores.std() * 2, test_scores.mean(), test_scores.std() * 2\n",
    "\n",
    "\n",
    "\n",
    "#--------------#\n",
    "# MLP benchmark\n",
    "#--------------#\n",
    "def MLP_benchmark(x_train, y_train, x_test, y_test, layer=(100, 50, 10, 2)):\n",
    "    '''\n",
    "    Do cross validation\n",
    "    Data: flatten and normalized \n",
    "    Return:\n",
    "        Accuracy socre mean and std\n",
    "    '''\n",
    "    interation = 10\n",
    "    train_scores = np.zeros(interation)\n",
    "    vali_scores = np.zeros(interation)\n",
    "    test_scores = np.zeros(interation)\n",
    "    for i in range(interation):\n",
    "        x_train_, y_train_, x_vali_, y_vali_ = split_data(x_train, y_train)\n",
    "        clf = MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                            hidden_layer_sizes=layer).fit(x_train_, y_train_)\n",
    "        train_scores[i] = clf.score(x_train_, y_train_)\n",
    "        vali_scores[i] = clf.score(x_vali_, y_vali_)\n",
    "        test_scores[i] = clf.score(x_test, y_test)\n",
    "    return train_scores.mean(), train_scores.std() * 2, vali_scores.mean(), vali_scores.std() * 2, test_scores.mean(), test_scores.std() * 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cnn_benchmark(x_train, y_train, x_test, y_test,lr=0.0001, decay=0.000001, batchsize=256, epochs=1):\n",
    "    '''\n",
    "    x_train is the whole data\n",
    "    Split trainning data to training data and validation data and feed in model\n",
    "    \n",
    "    Return the average trainning acc, vali acc, test acc\n",
    "    '''\n",
    "    interation = 10\n",
    "    train_scores = np.zeros(interation)\n",
    "    vali_scores = np.zeros(interation)\n",
    "    test_scores = np.zeros(interation)\n",
    "    for i in range(interation):\n",
    "        x_train_, y_train_, x_vali_, y_vali_ = split_data(x_train, y_train)\n",
    "        \n",
    "        model, history = train_cnn_model(\n",
    "            x_train_, y_train_, x_vali_, y_vali_, TYPE='with_noise', \n",
    "            lr=lr, decay=decay, batchsize=batchsize, epochs=epochs, T=None,loss_name=None)\n",
    "        \n",
    "        train_scores[i] = history.history['acc'][0]\n",
    "        vali_scores[i] = history.history['val_acc'][0]\n",
    "        prediction = model.predict(x_test)\n",
    "        \n",
    "        test_scores[i] = model.evaluate(x_test, y_test, batch_size=batchsize)[1]\n",
    "    return train_scores.mean(), train_scores.std() * 2, vali_scores.mean(), vali_scores.std() * 2, test_scores.mean(), test_scores.std() * 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8987999999999999, 0.004344824507388047, 0.6432500000000001, 0.02015068237057991, 0.7979, 0.01214742771124818)\n",
      "(0.7582625000000001, 0.2669911386638141, 0.61815, 0.046333681053851106, 0.6555500000000001, 0.2682153798722213)\n"
     ]
    }
   ],
   "source": [
    "# load data a3nd split data\n",
    "Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar = loaddata()\n",
    "\n",
    "Str_mnist = Str_mnist.flatten()\n",
    "Yts_mnist = Yts_mnist.flatten()\n",
    "\n",
    "Str_cifar = Str_cifar.flatten()\n",
    "Yts_cifar = Yts_cifar.flatten()\n",
    "\n",
    "\n",
    "# nomalization training data\n",
    "Xtr_mnist, Xts_mnist = standard(Xtr_mnist, Xts_mnist)\n",
    "Xtr_cifar, Xts_cifar = standard(Xtr_cifar, Xts_cifar)\n",
    "\n",
    "\n",
    "#--------------#\n",
    "# SVM benchmark\n",
    "#--------------#\n",
    "print(SVM_benchmark(Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, C=20))\n",
    "\n",
    "\n",
    "#--------------#\n",
    "# MLP benchmark\n",
    "#--------------#\n",
    "print(MLP_benchmark(Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, layer=(100, 50, 10, 2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9813875000000001, 0.001660007530103382, 0.605, 0.02261857643619509, 0.67035, 0.015026975743641858)\n",
      "(0.8232125000000001, 0.25046706495066373, 0.589, 0.040472212689696155, 0.67145, 0.19021695508024514)\n"
     ]
    }
   ],
   "source": [
    "#--------------#\n",
    "# SVM benchmark\n",
    "#--------------#\n",
    "\n",
    "print(SVM_benchmark(Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar, C=20))\n",
    "\n",
    "#--------------#\n",
    "# MLP benchmark\n",
    "#--------------#\n",
    "print(MLP_benchmark(Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar, layer=(100, 50, 10, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model with loss function correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark and cross validation of CNN without loss function correction on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (10000, 28, 28, 1), y_train (10000, 2) \n",
      "Xts_mnist (2000, 28, 28, 1), y_test (2000, 2)\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 3s 436ms/step - loss: 0.6760 - acc: 0.5634 - val_loss: 0.6607 - val_acc: 0.6060\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6517 - acc: 0.6078 - val_loss: 0.6432 - val_acc: 0.6225\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 39ms/step - loss: 0.6362 - acc: 0.6340 - val_loss: 0.6341 - val_acc: 0.6215\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6260 - acc: 0.6361 - val_loss: 0.6253 - val_acc: 0.6265\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6176 - acc: 0.6487 - val_loss: 0.6188 - val_acc: 0.6340\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6114 - acc: 0.6574 - val_loss: 0.6151 - val_acc: 0.6480\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6073 - acc: 0.6712 - val_loss: 0.6118 - val_acc: 0.6400\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6046 - acc: 0.6700 - val_loss: 0.6111 - val_acc: 0.6560\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6022 - acc: 0.6764 - val_loss: 0.6077 - val_acc: 0.6555\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6002 - acc: 0.6790 - val_loss: 0.6089 - val_acc: 0.6580\n",
      "2000/2000 [==============================] - 0s 12us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 148ms/step - loss: 0.6673 - acc: 0.6006 - val_loss: 0.6552 - val_acc: 0.5985\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6456 - acc: 0.6150 - val_loss: 0.6381 - val_acc: 0.6310\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6310 - acc: 0.6323 - val_loss: 0.6295 - val_acc: 0.6315\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6212 - acc: 0.6435 - val_loss: 0.6233 - val_acc: 0.6410\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6132 - acc: 0.6525 - val_loss: 0.6201 - val_acc: 0.6485\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6081 - acc: 0.6656 - val_loss: 0.6175 - val_acc: 0.6575\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6049 - acc: 0.6671 - val_loss: 0.6162 - val_acc: 0.6565\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6035 - acc: 0.6757 - val_loss: 0.6164 - val_acc: 0.6480\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 42ms/step - loss: 0.6018 - acc: 0.6676 - val_loss: 0.6151 - val_acc: 0.6695\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.5989 - acc: 0.6781 - val_loss: 0.6152 - val_acc: 0.6535\n",
      "2000/2000 [==============================] - 0s 13us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 138ms/step - loss: 0.6662 - acc: 0.6020 - val_loss: 0.6533 - val_acc: 0.5950\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6450 - acc: 0.6251 - val_loss: 0.6352 - val_acc: 0.6310\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6334 - acc: 0.6298 - val_loss: 0.6244 - val_acc: 0.6315\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 39ms/step - loss: 0.6242 - acc: 0.6337 - val_loss: 0.6166 - val_acc: 0.6410\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6182 - acc: 0.6500 - val_loss: 0.6121 - val_acc: 0.6455\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6131 - acc: 0.6532 - val_loss: 0.6060 - val_acc: 0.6725\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6099 - acc: 0.6606 - val_loss: 0.6036 - val_acc: 0.6700\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6068 - acc: 0.6666 - val_loss: 0.6027 - val_acc: 0.6690\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6049 - acc: 0.6677 - val_loss: 0.6000 - val_acc: 0.6755\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6040 - acc: 0.6733 - val_loss: 0.6021 - val_acc: 0.6665\n",
      "2000/2000 [==============================] - 0s 12us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 135ms/step - loss: 0.6757 - acc: 0.5829 - val_loss: 0.6626 - val_acc: 0.5965\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6496 - acc: 0.6185 - val_loss: 0.6493 - val_acc: 0.6200\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6369 - acc: 0.6343 - val_loss: 0.6395 - val_acc: 0.6170\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6267 - acc: 0.6362 - val_loss: 0.6313 - val_acc: 0.6215\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6191 - acc: 0.6411 - val_loss: 0.6261 - val_acc: 0.6390\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6141 - acc: 0.6609 - val_loss: 0.6221 - val_acc: 0.6345\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6103 - acc: 0.6562 - val_loss: 0.6211 - val_acc: 0.6465\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6057 - acc: 0.6697 - val_loss: 0.6186 - val_acc: 0.6410\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6040 - acc: 0.6699 - val_loss: 0.6172 - val_acc: 0.6460\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6012 - acc: 0.6735 - val_loss: 0.6161 - val_acc: 0.6485\n",
      "2000/2000 [==============================] - 0s 13us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 138ms/step - loss: 0.6704 - acc: 0.6039 - val_loss: 0.6662 - val_acc: 0.5870\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6480 - acc: 0.6186 - val_loss: 0.6484 - val_acc: 0.6250\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6344 - acc: 0.6321 - val_loss: 0.6400 - val_acc: 0.6205\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6238 - acc: 0.6397 - val_loss: 0.6333 - val_acc: 0.6190\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6156 - acc: 0.6417 - val_loss: 0.6291 - val_acc: 0.6195\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6094 - acc: 0.6608 - val_loss: 0.6266 - val_acc: 0.6340\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6050 - acc: 0.6627 - val_loss: 0.6244 - val_acc: 0.6490\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6019 - acc: 0.6749 - val_loss: 0.6268 - val_acc: 0.6345\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6009 - acc: 0.6725 - val_loss: 0.6236 - val_acc: 0.6535\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5979 - acc: 0.6768 - val_loss: 0.6238 - val_acc: 0.6525\n",
      "2000/2000 [==============================] - 0s 12us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 148ms/step - loss: 0.6800 - acc: 0.5561 - val_loss: 0.6610 - val_acc: 0.5990\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6557 - acc: 0.6016 - val_loss: 0.6407 - val_acc: 0.6195\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 42ms/step - loss: 0.6407 - acc: 0.6285 - val_loss: 0.6293 - val_acc: 0.6515\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6308 - acc: 0.6316 - val_loss: 0.6216 - val_acc: 0.6460\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6229 - acc: 0.6368 - val_loss: 0.6160 - val_acc: 0.6550\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6167 - acc: 0.6518 - val_loss: 0.6129 - val_acc: 0.6615\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 39ms/step - loss: 0.6125 - acc: 0.6563 - val_loss: 0.6098 - val_acc: 0.6695\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6088 - acc: 0.6652 - val_loss: 0.6078 - val_acc: 0.6685\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6063 - acc: 0.6660 - val_loss: 0.6065 - val_acc: 0.6735\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6040 - acc: 0.6694 - val_loss: 0.6062 - val_acc: 0.6685\n",
      "2000/2000 [==============================] - 0s 12us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 145ms/step - loss: 0.6826 - acc: 0.5456 - val_loss: 0.6632 - val_acc: 0.6045\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6598 - acc: 0.5994 - val_loss: 0.6508 - val_acc: 0.6045\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6467 - acc: 0.6104 - val_loss: 0.6407 - val_acc: 0.6340\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6362 - acc: 0.6332 - val_loss: 0.6331 - val_acc: 0.6365\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6274 - acc: 0.6357 - val_loss: 0.6262 - val_acc: 0.6395\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6198 - acc: 0.6410 - val_loss: 0.6217 - val_acc: 0.6365\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6134 - acc: 0.6543 - val_loss: 0.6179 - val_acc: 0.6400\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6085 - acc: 0.6560 - val_loss: 0.6159 - val_acc: 0.6600\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6049 - acc: 0.6692 - val_loss: 0.6144 - val_acc: 0.6580\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6017 - acc: 0.6684 - val_loss: 0.6136 - val_acc: 0.6585\n",
      "2000/2000 [==============================] - 0s 13us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 169ms/step - loss: 0.6842 - acc: 0.5396 - val_loss: 0.6590 - val_acc: 0.6090\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6575 - acc: 0.5989 - val_loss: 0.6461 - val_acc: 0.6145\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6424 - acc: 0.6238 - val_loss: 0.6399 - val_acc: 0.6320\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6325 - acc: 0.6365 - val_loss: 0.6308 - val_acc: 0.6400\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 42ms/step - loss: 0.6251 - acc: 0.6310 - val_loss: 0.6255 - val_acc: 0.6400\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6182 - acc: 0.6526 - val_loss: 0.6230 - val_acc: 0.6405\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6126 - acc: 0.6539 - val_loss: 0.6194 - val_acc: 0.6415\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6084 - acc: 0.6670 - val_loss: 0.6188 - val_acc: 0.6490\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6050 - acc: 0.6711 - val_loss: 0.6169 - val_acc: 0.6435\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6027 - acc: 0.6775 - val_loss: 0.6165 - val_acc: 0.6515\n",
      "2000/2000 [==============================] - 0s 12us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 154ms/step - loss: 0.6719 - acc: 0.6026 - val_loss: 0.6643 - val_acc: 0.5910\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6514 - acc: 0.6071 - val_loss: 0.6456 - val_acc: 0.6280\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6372 - acc: 0.6327 - val_loss: 0.6340 - val_acc: 0.6330\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6267 - acc: 0.6336 - val_loss: 0.6255 - val_acc: 0.6380\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6185 - acc: 0.6416 - val_loss: 0.6196 - val_acc: 0.6415\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6120 - acc: 0.6513 - val_loss: 0.6149 - val_acc: 0.6605\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6077 - acc: 0.6649 - val_loss: 0.6143 - val_acc: 0.6515\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6041 - acc: 0.6651 - val_loss: 0.6110 - val_acc: 0.6775\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6020 - acc: 0.6685 - val_loss: 0.6107 - val_acc: 0.6705\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.5997 - acc: 0.6734 - val_loss: 0.6102 - val_acc: 0.6765\n",
      "2000/2000 [==============================] - 0s 13us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 176ms/step - loss: 0.6828 - acc: 0.5452 - val_loss: 0.6601 - val_acc: 0.6065\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6579 - acc: 0.6002 - val_loss: 0.6450 - val_acc: 0.6215\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6444 - acc: 0.6246 - val_loss: 0.6361 - val_acc: 0.6480\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6351 - acc: 0.6296 - val_loss: 0.6279 - val_acc: 0.6440\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6270 - acc: 0.6334 - val_loss: 0.6223 - val_acc: 0.6445\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6200 - acc: 0.6343 - val_loss: 0.6178 - val_acc: 0.6495\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6143 - acc: 0.6578 - val_loss: 0.6146 - val_acc: 0.6595\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6098 - acc: 0.6518 - val_loss: 0.6124 - val_acc: 0.6640\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6072 - acc: 0.6692 - val_loss: 0.6109 - val_acc: 0.6625\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6030 - acc: 0.6693 - val_loss: 0.6102 - val_acc: 0.6615\n",
      "2000/2000 [==============================] - 0s 13us/step\n",
      "0.574$\\pm$0.051 & 0.599 $\\pm$0.014 & 0.850599996137619$\\pm$0.051683265145383885\n"
     ]
    }
   ],
   "source": [
    "#--------------------#\n",
    "# CNN benchmark for MNIST\n",
    "#--------------------#\n",
    "''' '''\n",
    "Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar = loaddata()\n",
    "\n",
    "Xtr_mnist,Xts_mnist = standard(Xtr_mnist,Xts_mnist)\n",
    "Xtr_mnist = Xtr_mnist.reshape(Xtr_mnist.shape[0], 28, 28,1)\n",
    "Xts_mnist = Xts_mnist.reshape(Xts_mnist.shape[0], 28, 28,1)\n",
    "\n",
    "y_train, y_test = one_hot_coding(Str_mnist,Yts_mnist)\n",
    "\n",
    "print('x_train {}, y_train {} \\nXts_mnist {}, y_test {}'.format(\n",
    "    Xtr_mnist.shape,y_train.shape,Xts_mnist.shape,y_test.shape))\n",
    "\n",
    "result = cnn_benchmark(\n",
    "     Xtr_mnist, y_train,Xts_mnist,y_test, lr=0.00001, decay=0.0000001, batchsize=1024, epochs=10)\n",
    "\n",
    "\n",
    "print('{}$\\pm${} & {} $\\pm${} & {}$\\pm${}'.format(round(result[0],3),round(result[1],3),round(result[2],3)\n",
    "                                                  ,round(result[3],3),result[4],result[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark and cross validation of CNN without loss function correction on Cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (10000, 32, 32, 3), y_train (10000, 2) \n",
      "Xts_mnist (2000, 32, 32, 3), y_test (2000, 2)\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 238ms/step - loss: 0.6888 - acc: 0.5791 - val_loss: 0.6698 - val_acc: 0.6030\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6488 - acc: 0.6278 - val_loss: 0.6438 - val_acc: 0.6140\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6330 - acc: 0.6446 - val_loss: 0.6372 - val_acc: 0.6430\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6210 - acc: 0.6553 - val_loss: 0.6375 - val_acc: 0.6460\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6146 - acc: 0.6715 - val_loss: 0.6346 - val_acc: 0.6450\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 51ms/step - loss: 0.6098 - acc: 0.6713 - val_loss: 0.6334 - val_acc: 0.6475\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6025 - acc: 0.6814 - val_loss: 0.6304 - val_acc: 0.6450\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5905 - acc: 0.6975 - val_loss: 0.6305 - val_acc: 0.6430\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5827 - acc: 0.7056 - val_loss: 0.6318 - val_acc: 0.6485\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.5730 - acc: 0.7156 - val_loss: 0.6286 - val_acc: 0.6475\n",
      "2000/2000 [==============================] - 0s 31us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 209ms/step - loss: 0.6798 - acc: 0.5913 - val_loss: 0.6709 - val_acc: 0.6040\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6435 - acc: 0.6332 - val_loss: 0.6485 - val_acc: 0.6180\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6282 - acc: 0.6455 - val_loss: 0.6432 - val_acc: 0.6270\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6204 - acc: 0.6560 - val_loss: 0.6405 - val_acc: 0.6365\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6131 - acc: 0.6675 - val_loss: 0.6371 - val_acc: 0.6420\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.6024 - acc: 0.6786 - val_loss: 0.6425 - val_acc: 0.6395\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5939 - acc: 0.6881 - val_loss: 0.6373 - val_acc: 0.6395\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5850 - acc: 0.7000 - val_loss: 0.6399 - val_acc: 0.6470\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5762 - acc: 0.7083 - val_loss: 0.6446 - val_acc: 0.6515\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5678 - acc: 0.7199 - val_loss: 0.6395 - val_acc: 0.6485\n",
      "2000/2000 [==============================] - 0s 31us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 217ms/step - loss: 0.6656 - acc: 0.6043 - val_loss: 0.6299 - val_acc: 0.6470\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6341 - acc: 0.6408 - val_loss: 0.6218 - val_acc: 0.6570\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6198 - acc: 0.6616 - val_loss: 0.6184 - val_acc: 0.6565\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6094 - acc: 0.6782 - val_loss: 0.6174 - val_acc: 0.6575\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5990 - acc: 0.6879 - val_loss: 0.6154 - val_acc: 0.6620\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5889 - acc: 0.6993 - val_loss: 0.6131 - val_acc: 0.6525\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.5776 - acc: 0.7117 - val_loss: 0.6225 - val_acc: 0.6655\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5688 - acc: 0.7190 - val_loss: 0.6131 - val_acc: 0.6565\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5581 - acc: 0.7239 - val_loss: 0.6191 - val_acc: 0.6600\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5440 - acc: 0.7412 - val_loss: 0.6200 - val_acc: 0.6520\n",
      "2000/2000 [==============================] - 0s 31us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 218ms/step - loss: 0.6811 - acc: 0.5802 - val_loss: 0.6495 - val_acc: 0.6135\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6424 - acc: 0.6246 - val_loss: 0.6374 - val_acc: 0.6470\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6259 - acc: 0.6591 - val_loss: 0.6321 - val_acc: 0.6465\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.6152 - acc: 0.6718 - val_loss: 0.6287 - val_acc: 0.6510\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 51ms/step - loss: 0.6051 - acc: 0.6813 - val_loss: 0.6273 - val_acc: 0.6465\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5967 - acc: 0.6880 - val_loss: 0.6292 - val_acc: 0.6445\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5888 - acc: 0.6963 - val_loss: 0.6249 - val_acc: 0.6545\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5746 - acc: 0.7167 - val_loss: 0.6259 - val_acc: 0.6585\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5631 - acc: 0.7309 - val_loss: 0.6232 - val_acc: 0.6590\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5512 - acc: 0.7367 - val_loss: 0.6339 - val_acc: 0.6665\n",
      "2000/2000 [==============================] - 0s 30us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 233ms/step - loss: 0.6554 - acc: 0.6075 - val_loss: 0.6376 - val_acc: 0.6245\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6291 - acc: 0.6504 - val_loss: 0.6478 - val_acc: 0.6320\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6177 - acc: 0.6593 - val_loss: 0.6365 - val_acc: 0.6415\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6072 - acc: 0.6777 - val_loss: 0.6367 - val_acc: 0.6485\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5990 - acc: 0.6867 - val_loss: 0.6398 - val_acc: 0.6465\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5881 - acc: 0.6986 - val_loss: 0.6280 - val_acc: 0.6545\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5768 - acc: 0.7132 - val_loss: 0.6299 - val_acc: 0.6460\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 51ms/step - loss: 0.5679 - acc: 0.7242 - val_loss: 0.6318 - val_acc: 0.6410\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5611 - acc: 0.7255 - val_loss: 0.6331 - val_acc: 0.6550\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 55ms/step - loss: 0.5426 - acc: 0.7487 - val_loss: 0.6321 - val_acc: 0.6515\n",
      "2000/2000 [==============================] - 0s 30us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 226ms/step - loss: 0.6727 - acc: 0.5786 - val_loss: 0.6377 - val_acc: 0.6345\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6372 - acc: 0.6428 - val_loss: 0.6288 - val_acc: 0.6400\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6238 - acc: 0.6571 - val_loss: 0.6226 - val_acc: 0.6540\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6113 - acc: 0.6780 - val_loss: 0.6199 - val_acc: 0.6520\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6019 - acc: 0.6841 - val_loss: 0.6225 - val_acc: 0.6465\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 51ms/step - loss: 0.5925 - acc: 0.6937 - val_loss: 0.6188 - val_acc: 0.6585\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5819 - acc: 0.7045 - val_loss: 0.6189 - val_acc: 0.6610\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5666 - acc: 0.7235 - val_loss: 0.6163 - val_acc: 0.6605\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 54ms/step - loss: 0.5531 - acc: 0.7401 - val_loss: 0.6173 - val_acc: 0.6605\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5410 - acc: 0.7512 - val_loss: 0.6180 - val_acc: 0.6625\n",
      "2000/2000 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 226ms/step - loss: 0.6586 - acc: 0.6092 - val_loss: 0.6289 - val_acc: 0.6640\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6292 - acc: 0.6523 - val_loss: 0.6139 - val_acc: 0.6485\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6145 - acc: 0.6657 - val_loss: 0.6185 - val_acc: 0.6630\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6044 - acc: 0.6820 - val_loss: 0.6106 - val_acc: 0.6640\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5929 - acc: 0.6910 - val_loss: 0.6122 - val_acc: 0.6650\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.5819 - acc: 0.7029 - val_loss: 0.6137 - val_acc: 0.6590\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 56ms/step - loss: 0.5721 - acc: 0.7120 - val_loss: 0.6196 - val_acc: 0.6615\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5603 - acc: 0.7280 - val_loss: 0.6215 - val_acc: 0.6410\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5450 - acc: 0.7414 - val_loss: 0.6209 - val_acc: 0.6585\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5370 - acc: 0.7491 - val_loss: 0.6374 - val_acc: 0.6420\n",
      "2000/2000 [==============================] - 0s 33us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 233ms/step - loss: 0.7088 - acc: 0.5765 - val_loss: 0.6629 - val_acc: 0.5950\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6464 - acc: 0.6190 - val_loss: 0.6481 - val_acc: 0.6370\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6340 - acc: 0.6368 - val_loss: 0.6465 - val_acc: 0.6290\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6247 - acc: 0.6490 - val_loss: 0.6427 - val_acc: 0.6290\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 52ms/step - loss: 0.6178 - acc: 0.6619 - val_loss: 0.6363 - val_acc: 0.6500\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6107 - acc: 0.6717 - val_loss: 0.6355 - val_acc: 0.6475\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6030 - acc: 0.6794 - val_loss: 0.6440 - val_acc: 0.6270\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5990 - acc: 0.6831 - val_loss: 0.6335 - val_acc: 0.6580\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5894 - acc: 0.6951 - val_loss: 0.6321 - val_acc: 0.6535\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.5815 - acc: 0.7053 - val_loss: 0.6331 - val_acc: 0.6495\n",
      "2000/2000 [==============================] - 0s 31us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 257ms/step - loss: 0.6838 - acc: 0.5781 - val_loss: 0.6515 - val_acc: 0.6090\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6449 - acc: 0.6299 - val_loss: 0.6384 - val_acc: 0.6135\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6291 - acc: 0.6397 - val_loss: 0.6282 - val_acc: 0.6455\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6195 - acc: 0.6636 - val_loss: 0.6269 - val_acc: 0.6450\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6120 - acc: 0.6698 - val_loss: 0.6238 - val_acc: 0.6515\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 54ms/step - loss: 0.6055 - acc: 0.6770 - val_loss: 0.6276 - val_acc: 0.6585\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5995 - acc: 0.6842 - val_loss: 0.6237 - val_acc: 0.6595\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 51ms/step - loss: 0.5917 - acc: 0.6915 - val_loss: 0.6211 - val_acc: 0.6620\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5815 - acc: 0.7001 - val_loss: 0.6225 - val_acc: 0.6645\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5747 - acc: 0.7085 - val_loss: 0.6220 - val_acc: 0.6615\n",
      "2000/2000 [==============================] - 0s 32us/step\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 242ms/step - loss: 0.6748 - acc: 0.5895 - val_loss: 0.6682 - val_acc: 0.5915\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6397 - acc: 0.6309 - val_loss: 0.6441 - val_acc: 0.6145\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6235 - acc: 0.6534 - val_loss: 0.6380 - val_acc: 0.6365\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6140 - acc: 0.6642 - val_loss: 0.6397 - val_acc: 0.6355\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6051 - acc: 0.6758 - val_loss: 0.6380 - val_acc: 0.6390\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5941 - acc: 0.6854 - val_loss: 0.6354 - val_acc: 0.6500\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5862 - acc: 0.6995 - val_loss: 0.6350 - val_acc: 0.6415\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5767 - acc: 0.7039 - val_loss: 0.6343 - val_acc: 0.6425\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5638 - acc: 0.7202 - val_loss: 0.6349 - val_acc: 0.6460\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 51ms/step - loss: 0.5553 - acc: 0.7264 - val_loss: 0.6378 - val_acc: 0.6510\n",
      "2000/2000 [==============================] - 0s 37us/step\n",
      "0.589$\\pm$0.026 & 0.619 $\\pm$0.045 & 0.8197999990463257$\\pm$0.06839766812811501\n"
     ]
    }
   ],
   "source": [
    "#--------------------#\n",
    "# CNN benchmark for cifa\n",
    "#--------------------#\n",
    "\n",
    "Xtr_cifar,Xts_cifar = standard(Xtr_cifar,Xts_cifar)\n",
    "\n",
    "Xtr_cifar = Xtr_cifar.reshape(Xtr_cifar.shape[0], 32,32,3)\n",
    "Xts_cifar = Xts_cifar.reshape(Xts_cifar.shape[0], 32,32,3)\n",
    "y_train, y_test = one_hot_coding(Str_cifar,Yts_cifar)\n",
    "\n",
    "print('x_train {}, y_train {} \\nXts_mnist {}, y_test {}'.format(\n",
    "    Xtr_cifar.shape,y_train.shape,Xts_cifar.shape,y_test.shape))\n",
    "\n",
    "result = cnn_benchmark(\n",
    "     Xtr_cifar, y_train,Xts_cifar,y_test, lr=0.00005, decay=0.0000001, batchsize=1024, epochs=10)\n",
    "\n",
    "\n",
    "print('{}$\\pm${} & {} $\\pm${} & {}$\\pm${}'.format(round(result[0],3),round(result[1],3),round(result[2],3)\n",
    "                                                  ,round(result[3],3),result[4],result[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute matrix T (flip rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_loss_correct_compute_T(x_train,y_train,x_test,y_test,iteration=10,lr=0.00005, decay=0.0000001, \n",
    "                     batchsize=1024,epochs=15,TYPE='mnist',loss_name='forward'):\n",
    "    if TYPE=='mnist':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
    "        y_train, y_test = one_hot_coding(y_train,y_test)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], 32,32,3)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 32,32,3)\n",
    "        y_train, y_test = one_hot_coding(y_train,y_test)\n",
    "        \n",
    "    x_train_= x_train.copy()\n",
    "    y_train_=y_train.copy()\n",
    "    \n",
    "    T = np.zeros((iteration,2,2))\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        \n",
    "        x_train, y_train, x_vali, y_vali = split_data(x_train_,y_train_,part=0.8)\n",
    "        \n",
    "        print('\\nIteration {}\\n'.format(i))\n",
    "        \n",
    "        # Estimate the T\n",
    "        print('\\nTrain model with noise \\n')\n",
    "        model_noise,history_noise = train_cnn_model(x_train, y_train, x_vali, y_vali, TYPE='with_noise',\n",
    "                            lr=lr, decay=decay, batchsize=batchsize, epochs=epochs)\n",
    "        \n",
    "        prediction_noise = model_noise.predict(x_train)\n",
    "        T[i] = compute_T(prediction_noise)\n",
    "    \n",
    "    # Return the average of T\n",
    "    return (np.mean(T,axis=0),\n",
    "            np.std(T,axis=0))\n",
    "\n",
    "# Implement the given flip rate to train model \n",
    "def cnn_loss_correct(x_train,y_train,x_test,y_test,iteration=10,lr=0.00005, decay=0.0000001, \n",
    "                     batchsize=1024,epochs=15,TYPE='mnist',loss_name='forward'):\n",
    "    if TYPE=='mnist':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 28,28,1)\n",
    "        y_train, y_test = one_hot_coding(y_train,y_test)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], 32,32,3)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 32,32,3)\n",
    "        y_train, y_test = one_hot_coding(y_train,y_test)\n",
    "        \n",
    "    x_train_= x_train.copy()\n",
    "    y_train_=y_train.copy()\n",
    "    \n",
    "    T = np.zeros((iteration,2,2))\n",
    "    \n",
    "    no_noise_accuracy = np.zeros((iteration))\n",
    "    validation_accuracy = np.zeros((iteration))\n",
    "    train_accuracy = np.zeros((iteration))\n",
    "    for i in range(iteration):\n",
    "        \n",
    "        x_train, y_train, x_vali, y_vali = split_data(x_train_,y_train_,part=0.8)\n",
    "        \n",
    "        print('\\nIteration {}\\n'.format(i))\n",
    "        \n",
    "        print('\\nTrain model with loss orrection \\n')\n",
    "        \n",
    "        # Given the T (flip rate) \n",
    "        T = np.array([[0.8,0.2],[0.4,0.6]])\n",
    "        model, history = train_cnn_model(x_train, y_train, x_vali, y_vali, TYPE='without_noise',\n",
    "                            lr=lr, decay=decay, batchsize=batchsize, epochs=epochs,T=T,loss_name=loss_name)\n",
    "        \n",
    "        train_accuracy[i] = model.evaluate(x_train, y_train)[1]\n",
    "        validation_accuracy[i] = model.evaluate(x_vali, y_vali)[1]\n",
    "        no_noise_accuracy[i] = model.evaluate(x_test,y_test)[1]\n",
    "        \n",
    "    model.summary()\n",
    "    return (np.mean(train_accuracy),train_accuracy.std(),\n",
    "            np.mean(validation_accuracy),validation_accuracy.std(),\n",
    "            np.mean(no_noise_accuracy),no_noise_accuracy.std(),\n",
    "            np.mean(T,axis=0),\n",
    "            np.std(T,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 226ms/step - loss: 0.6795 - acc: 0.5592 - val_loss: 0.6642 - val_acc: 0.5965\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6485 - acc: 0.6184 - val_loss: 0.6488 - val_acc: 0.6215\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6351 - acc: 0.6342 - val_loss: 0.6373 - val_acc: 0.6225\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6246 - acc: 0.6377 - val_loss: 0.6261 - val_acc: 0.6235\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6174 - acc: 0.6445 - val_loss: 0.6189 - val_acc: 0.6495\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6134 - acc: 0.6541 - val_loss: 0.6159 - val_acc: 0.6420\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6095 - acc: 0.6649 - val_loss: 0.6123 - val_acc: 0.6585\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6075 - acc: 0.6616 - val_loss: 0.6102 - val_acc: 0.6700\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6051 - acc: 0.6677 - val_loss: 0.6092 - val_acc: 0.6635\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6030 - acc: 0.6699 - val_loss: 0.6087 - val_acc: 0.6640\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 233ms/step - loss: 0.6767 - acc: 0.5702 - val_loss: 0.6557 - val_acc: 0.6105\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6538 - acc: 0.6009 - val_loss: 0.6391 - val_acc: 0.6430\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6408 - acc: 0.6304 - val_loss: 0.6306 - val_acc: 0.6425\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6320 - acc: 0.6333 - val_loss: 0.6219 - val_acc: 0.6475\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6244 - acc: 0.6402 - val_loss: 0.6169 - val_acc: 0.6560\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6181 - acc: 0.6427 - val_loss: 0.6123 - val_acc: 0.6605\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6139 - acc: 0.6571 - val_loss: 0.6099 - val_acc: 0.6610\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6104 - acc: 0.6638 - val_loss: 0.6070 - val_acc: 0.6595\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6078 - acc: 0.6680 - val_loss: 0.6062 - val_acc: 0.6665\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6055 - acc: 0.6676 - val_loss: 0.6048 - val_acc: 0.6655\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 239ms/step - loss: 0.6638 - acc: 0.6063 - val_loss: 0.6610 - val_acc: 0.5920\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6420 - acc: 0.6308 - val_loss: 0.6453 - val_acc: 0.6180\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6289 - acc: 0.6360 - val_loss: 0.6322 - val_acc: 0.6220\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6189 - acc: 0.6409 - val_loss: 0.6260 - val_acc: 0.6315\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6123 - acc: 0.6537 - val_loss: 0.6188 - val_acc: 0.6550\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6086 - acc: 0.6562 - val_loss: 0.6148 - val_acc: 0.6695\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6051 - acc: 0.6663 - val_loss: 0.6216 - val_acc: 0.6450\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6033 - acc: 0.6691 - val_loss: 0.6156 - val_acc: 0.6635\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6005 - acc: 0.6707 - val_loss: 0.6132 - val_acc: 0.6670\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5991 - acc: 0.6774 - val_loss: 0.6219 - val_acc: 0.6400\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 243ms/step - loss: 0.6784 - acc: 0.5603 - val_loss: 0.6571 - val_acc: 0.6020\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6539 - acc: 0.6032 - val_loss: 0.6399 - val_acc: 0.6345\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6399 - acc: 0.6311 - val_loss: 0.6296 - val_acc: 0.6355\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6297 - acc: 0.6321 - val_loss: 0.6202 - val_acc: 0.6395\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6217 - acc: 0.6437 - val_loss: 0.6155 - val_acc: 0.6490\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6161 - acc: 0.6532 - val_loss: 0.6094 - val_acc: 0.6490\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6116 - acc: 0.6593 - val_loss: 0.6063 - val_acc: 0.6545\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6088 - acc: 0.6668 - val_loss: 0.6052 - val_acc: 0.6640\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6064 - acc: 0.6701 - val_loss: 0.6028 - val_acc: 0.6620\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6039 - acc: 0.6731 - val_loss: 0.6017 - val_acc: 0.6650\n",
      "\n",
      "Iteration 4\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 269ms/step - loss: 0.6746 - acc: 0.5775 - val_loss: 0.6536 - val_acc: 0.6165\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6492 - acc: 0.6140 - val_loss: 0.6471 - val_acc: 0.6235\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6370 - acc: 0.6330 - val_loss: 0.6396 - val_acc: 0.6235\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6262 - acc: 0.6366 - val_loss: 0.6310 - val_acc: 0.6270\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6187 - acc: 0.6510 - val_loss: 0.6241 - val_acc: 0.6380\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6125 - acc: 0.6529 - val_loss: 0.6236 - val_acc: 0.6415\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6085 - acc: 0.6708 - val_loss: 0.6195 - val_acc: 0.6470\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6049 - acc: 0.6697 - val_loss: 0.6202 - val_acc: 0.6455\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6024 - acc: 0.6782 - val_loss: 0.6181 - val_acc: 0.6505\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5997 - acc: 0.6773 - val_loss: 0.6181 - val_acc: 0.6510\n",
      "\n",
      "Iteration 5\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 251ms/step - loss: 0.6851 - acc: 0.5387 - val_loss: 0.6714 - val_acc: 0.5855\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6551 - acc: 0.6046 - val_loss: 0.6564 - val_acc: 0.5900\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6405 - acc: 0.6308 - val_loss: 0.6449 - val_acc: 0.6140\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6316 - acc: 0.6368 - val_loss: 0.6377 - val_acc: 0.6140\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6232 - acc: 0.6369 - val_loss: 0.6281 - val_acc: 0.6250\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6170 - acc: 0.6430 - val_loss: 0.6221 - val_acc: 0.6335\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6124 - acc: 0.6573 - val_loss: 0.6173 - val_acc: 0.6450\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6083 - acc: 0.6560 - val_loss: 0.6138 - val_acc: 0.6560\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6065 - acc: 0.6660 - val_loss: 0.6135 - val_acc: 0.6455\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6040 - acc: 0.6659 - val_loss: 0.6093 - val_acc: 0.6710\n",
      "\n",
      "Iteration 6\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 257ms/step - loss: 0.6739 - acc: 0.5857 - val_loss: 0.6586 - val_acc: 0.6000\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6528 - acc: 0.6051 - val_loss: 0.6437 - val_acc: 0.6315\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6409 - acc: 0.6264 - val_loss: 0.6336 - val_acc: 0.6360\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6315 - acc: 0.6291 - val_loss: 0.6251 - val_acc: 0.6385\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6236 - acc: 0.6342 - val_loss: 0.6182 - val_acc: 0.6440\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6179 - acc: 0.6438 - val_loss: 0.6135 - val_acc: 0.6440\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6127 - acc: 0.6542 - val_loss: 0.6103 - val_acc: 0.6680\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 42ms/step - loss: 0.6091 - acc: 0.6548 - val_loss: 0.6083 - val_acc: 0.6690\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6073 - acc: 0.6716 - val_loss: 0.6074 - val_acc: 0.6705\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6049 - acc: 0.6617 - val_loss: 0.6064 - val_acc: 0.6805\n",
      "\n",
      "Iteration 7\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 261ms/step - loss: 0.6732 - acc: 0.5950 - val_loss: 0.6592 - val_acc: 0.6055\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6556 - acc: 0.6024 - val_loss: 0.6436 - val_acc: 0.6230\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6422 - acc: 0.6276 - val_loss: 0.6336 - val_acc: 0.6385\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6329 - acc: 0.6313 - val_loss: 0.6252 - val_acc: 0.6365\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6249 - acc: 0.6343 - val_loss: 0.6191 - val_acc: 0.6480\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6184 - acc: 0.6445 - val_loss: 0.6141 - val_acc: 0.6540\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6134 - acc: 0.6528 - val_loss: 0.6107 - val_acc: 0.6515\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6101 - acc: 0.6637 - val_loss: 0.6077 - val_acc: 0.6505\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6074 - acc: 0.6683 - val_loss: 0.6059 - val_acc: 0.6550\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6048 - acc: 0.6740 - val_loss: 0.6040 - val_acc: 0.6600\n",
      "\n",
      "Iteration 8\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 264ms/step - loss: 0.6783 - acc: 0.5635 - val_loss: 0.6511 - val_acc: 0.6220\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6548 - acc: 0.6055 - val_loss: 0.6371 - val_acc: 0.6450\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6408 - acc: 0.6307 - val_loss: 0.6315 - val_acc: 0.6400\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6313 - acc: 0.6329 - val_loss: 0.6190 - val_acc: 0.6405\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6235 - acc: 0.6350 - val_loss: 0.6149 - val_acc: 0.6580\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6173 - acc: 0.6587 - val_loss: 0.6081 - val_acc: 0.6580\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6125 - acc: 0.6539 - val_loss: 0.6055 - val_acc: 0.6660\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6101 - acc: 0.6679 - val_loss: 0.6025 - val_acc: 0.6680\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 42ms/step - loss: 0.6080 - acc: 0.6647 - val_loss: 0.6025 - val_acc: 0.6680\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6057 - acc: 0.6713 - val_loss: 0.5992 - val_acc: 0.6680\n",
      "\n",
      "Iteration 9\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 274ms/step - loss: 0.6714 - acc: 0.5984 - val_loss: 0.6624 - val_acc: 0.5975\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6499 - acc: 0.6100 - val_loss: 0.6464 - val_acc: 0.6260\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6367 - acc: 0.6354 - val_loss: 0.6376 - val_acc: 0.6245\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6269 - acc: 0.6358 - val_loss: 0.6302 - val_acc: 0.6270\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6189 - acc: 0.6360 - val_loss: 0.6241 - val_acc: 0.6455\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6143 - acc: 0.6553 - val_loss: 0.6210 - val_acc: 0.6485\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6097 - acc: 0.6490 - val_loss: 0.6179 - val_acc: 0.6670\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6060 - acc: 0.6680 - val_loss: 0.6172 - val_acc: 0.6565\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6029 - acc: 0.6680 - val_loss: 0.6149 - val_acc: 0.6665\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6013 - acc: 0.6715 - val_loss: 0.6142 - val_acc: 0.6645\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type numpy.ndarray doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-09f13df723fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the average T and std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}$\\pm${}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: type numpy.ndarray doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar = loaddata()\n",
    "Xtr_mnist,Xts_mnist = standard(Xtr_mnist,Xts_mnist)\n",
    "\n",
    "result = cnn_loss_correct_compute_T(Xtr_mnist,Str_mnist,Xts_mnist,Yts_mnist,iteration=10,lr=0.00001, decay=0.0000001, \n",
    "                     batchsize=1024,epochs=10,TYPE='mnist',loss_name = 'forward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81990661 0.18009339]\n",
      " [0.40075063 0.59924937]]  \n",
      " \n",
      "  [[0.01070622 0.01070623]\n",
      " [0.01391703 0.01391703]]\n"
     ]
    }
   ],
   "source": [
    "# Print the average T and std\n",
    "print('{}  \\n \\n  {}'.format(result[0],result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use given T to train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 263ms/step - loss: 0.6569 - acc: 0.5999 - val_loss: 0.6381 - val_acc: 0.6560\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6288 - acc: 0.6677 - val_loss: 0.6195 - val_acc: 0.6635\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6140 - acc: 0.6713 - val_loss: 0.6138 - val_acc: 0.6470\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 33ms/step - loss: 0.6080 - acc: 0.6699 - val_loss: 0.6045 - val_acc: 0.6675\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 43ms/step - loss: 0.6040 - acc: 0.6706 - val_loss: 0.6031 - val_acc: 0.6745\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6006 - acc: 0.6785 - val_loss: 0.6009 - val_acc: 0.6735\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 39ms/step - loss: 0.5987 - acc: 0.6831 - val_loss: 0.5999 - val_acc: 0.6775\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.5975 - acc: 0.6853 - val_loss: 0.5992 - val_acc: 0.6790\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.5970 - acc: 0.6860 - val_loss: 0.5988 - val_acc: 0.6755\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.5955 - acc: 0.6876 - val_loss: 0.5975 - val_acc: 0.6795\n",
      "8000/8000 [==============================] - 1s 110us/step\n",
      "2000/2000 [==============================] - 0s 113us/step\n",
      "2000/2000 [==============================] - 0s 114us/step\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 148ms/step - loss: 0.6532 - acc: 0.6026 - val_loss: 0.6329 - val_acc: 0.6675\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6286 - acc: 0.6679 - val_loss: 0.6155 - val_acc: 0.6815\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6161 - acc: 0.6638 - val_loss: 0.6056 - val_acc: 0.6905\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6092 - acc: 0.6704 - val_loss: 0.5989 - val_acc: 0.6920\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.6051 - acc: 0.6727 - val_loss: 0.5968 - val_acc: 0.6860\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6036 - acc: 0.6770 - val_loss: 0.5955 - val_acc: 0.6860\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6010 - acc: 0.6767 - val_loss: 0.5940 - val_acc: 0.6975\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6009 - acc: 0.6737 - val_loss: 0.5947 - val_acc: 0.6830\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5986 - acc: 0.6828 - val_loss: 0.5934 - val_acc: 0.6895\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.5967 - acc: 0.6868 - val_loss: 0.5937 - val_acc: 0.6830\n",
      "8000/8000 [==============================] - 1s 112us/step\n",
      "2000/2000 [==============================] - 0s 112us/step\n",
      "2000/2000 [==============================] - 0s 117us/step\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 159ms/step - loss: 0.6571 - acc: 0.6028 - val_loss: 0.6431 - val_acc: 0.6305\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6314 - acc: 0.6587 - val_loss: 0.6267 - val_acc: 0.6510\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6147 - acc: 0.6718 - val_loss: 0.6181 - val_acc: 0.6500\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6059 - acc: 0.6758 - val_loss: 0.6116 - val_acc: 0.6565\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6020 - acc: 0.6756 - val_loss: 0.6121 - val_acc: 0.6700\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5995 - acc: 0.6796 - val_loss: 0.6075 - val_acc: 0.6625\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.5975 - acc: 0.6839 - val_loss: 0.6064 - val_acc: 0.6660\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5957 - acc: 0.6859 - val_loss: 0.6058 - val_acc: 0.6690\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.5936 - acc: 0.6910 - val_loss: 0.6051 - val_acc: 0.6720\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5944 - acc: 0.6854 - val_loss: 0.6053 - val_acc: 0.6620\n",
      "8000/8000 [==============================] - 1s 85us/step\n",
      "2000/2000 [==============================] - 0s 90us/step\n",
      "2000/2000 [==============================] - 0s 94us/step\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 156ms/step - loss: 0.6588 - acc: 0.5857 - val_loss: 0.6303 - val_acc: 0.6585\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6343 - acc: 0.6561 - val_loss: 0.6119 - val_acc: 0.6755\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6192 - acc: 0.6638 - val_loss: 0.6008 - val_acc: 0.6810\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.6116 - acc: 0.6713 - val_loss: 0.5977 - val_acc: 0.6660\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6073 - acc: 0.6734 - val_loss: 0.5939 - val_acc: 0.6730\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6041 - acc: 0.6786 - val_loss: 0.5914 - val_acc: 0.6850\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6024 - acc: 0.6747 - val_loss: 0.5923 - val_acc: 0.6915\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6001 - acc: 0.6848 - val_loss: 0.5896 - val_acc: 0.6865\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5986 - acc: 0.6847 - val_loss: 0.5908 - val_acc: 0.6745\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.5985 - acc: 0.6810 - val_loss: 0.5898 - val_acc: 0.6925\n",
      "8000/8000 [==============================] - 1s 75us/step\n",
      "2000/2000 [==============================] - 0s 82us/step\n",
      "2000/2000 [==============================] - 0s 84us/step\n",
      "\n",
      "Iteration 4\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 158ms/step - loss: 0.6578 - acc: 0.6167 - val_loss: 0.6398 - val_acc: 0.6580\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6292 - acc: 0.6654 - val_loss: 0.6200 - val_acc: 0.6665\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6132 - acc: 0.6689 - val_loss: 0.6091 - val_acc: 0.6700\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 36ms/step - loss: 0.6056 - acc: 0.6701 - val_loss: 0.6048 - val_acc: 0.6770\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.6018 - acc: 0.6792 - val_loss: 0.6042 - val_acc: 0.6640\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6005 - acc: 0.6805 - val_loss: 0.6014 - val_acc: 0.6745\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5981 - acc: 0.6840 - val_loss: 0.6016 - val_acc: 0.6720\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.5967 - acc: 0.6841 - val_loss: 0.6008 - val_acc: 0.6820\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5949 - acc: 0.6839 - val_loss: 0.6012 - val_acc: 0.6805\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.5952 - acc: 0.6878 - val_loss: 0.6016 - val_acc: 0.6680\n",
      "8000/8000 [==============================] - 1s 118us/step\n",
      "2000/2000 [==============================] - 0s 118us/step\n",
      "2000/2000 [==============================] - 0s 122us/step\n",
      "\n",
      "Iteration 5\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 171ms/step - loss: 0.6614 - acc: 0.6118 - val_loss: 0.6338 - val_acc: 0.6600\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6360 - acc: 0.6618 - val_loss: 0.6129 - val_acc: 0.6725\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6185 - acc: 0.6699 - val_loss: 0.6012 - val_acc: 0.6735\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 39ms/step - loss: 0.6089 - acc: 0.6716 - val_loss: 0.5967 - val_acc: 0.6755\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6047 - acc: 0.6769 - val_loss: 0.5944 - val_acc: 0.6760\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6031 - acc: 0.6733 - val_loss: 0.5949 - val_acc: 0.6660\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6009 - acc: 0.6795 - val_loss: 0.5931 - val_acc: 0.6705\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5990 - acc: 0.6839 - val_loss: 0.5914 - val_acc: 0.6895\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.5976 - acc: 0.6827 - val_loss: 0.5907 - val_acc: 0.6875\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5960 - acc: 0.6856 - val_loss: 0.5903 - val_acc: 0.6885\n",
      "8000/8000 [==============================] - 0s 62us/step\n",
      "2000/2000 [==============================] - 0s 65us/step\n",
      "2000/2000 [==============================] - 0s 68us/step\n",
      "\n",
      "Iteration 6\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 165ms/step - loss: 0.6550 - acc: 0.6050 - val_loss: 0.6353 - val_acc: 0.6595\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6286 - acc: 0.6582 - val_loss: 0.6162 - val_acc: 0.6680\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6137 - acc: 0.6689 - val_loss: 0.6075 - val_acc: 0.6695\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.6067 - acc: 0.6723 - val_loss: 0.6028 - val_acc: 0.6705\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6046 - acc: 0.6731 - val_loss: 0.5990 - val_acc: 0.6840\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6014 - acc: 0.6734 - val_loss: 0.5982 - val_acc: 0.6910\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.5993 - acc: 0.6832 - val_loss: 0.5967 - val_acc: 0.6890\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.5972 - acc: 0.6863 - val_loss: 0.5979 - val_acc: 0.6780\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.5963 - acc: 0.6865 - val_loss: 0.5982 - val_acc: 0.6735\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.5939 - acc: 0.6907 - val_loss: 0.5966 - val_acc: 0.6840\n",
      "8000/8000 [==============================] - 1s 113us/step\n",
      "2000/2000 [==============================] - 0s 120us/step\n",
      "2000/2000 [==============================] - 0s 125us/step\n",
      "\n",
      "Iteration 7\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 167ms/step - loss: 0.6551 - acc: 0.6078 - val_loss: 0.6435 - val_acc: 0.6335\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6281 - acc: 0.6593 - val_loss: 0.6286 - val_acc: 0.6455\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.6127 - acc: 0.6727 - val_loss: 0.6204 - val_acc: 0.6545\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 39ms/step - loss: 0.6051 - acc: 0.6779 - val_loss: 0.6169 - val_acc: 0.6565\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.6002 - acc: 0.6795 - val_loss: 0.6151 - val_acc: 0.6585\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 39ms/step - loss: 0.5980 - acc: 0.6835 - val_loss: 0.6138 - val_acc: 0.6600\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 37ms/step - loss: 0.5965 - acc: 0.6852 - val_loss: 0.6137 - val_acc: 0.6580\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5944 - acc: 0.6864 - val_loss: 0.6124 - val_acc: 0.6590\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.5916 - acc: 0.6915 - val_loss: 0.6120 - val_acc: 0.6590\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5911 - acc: 0.6942 - val_loss: 0.6118 - val_acc: 0.6565\n",
      "8000/8000 [==============================] - 1s 114us/step\n",
      "2000/2000 [==============================] - 0s 123us/step\n",
      "2000/2000 [==============================] - 0s 127us/step\n",
      "\n",
      "Iteration 8\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 172ms/step - loss: 0.6566 - acc: 0.6344 - val_loss: 0.6341 - val_acc: 0.6510\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6282 - acc: 0.6600 - val_loss: 0.6147 - val_acc: 0.6670\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6137 - acc: 0.6669 - val_loss: 0.6057 - val_acc: 0.6730\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6071 - acc: 0.6748 - val_loss: 0.6018 - val_acc: 0.6735\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.6032 - acc: 0.6734 - val_loss: 0.6008 - val_acc: 0.6780\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6006 - acc: 0.6802 - val_loss: 0.6001 - val_acc: 0.6715\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5985 - acc: 0.6839 - val_loss: 0.5990 - val_acc: 0.6710\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.5967 - acc: 0.6842 - val_loss: 0.5970 - val_acc: 0.6785\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 35ms/step - loss: 0.5957 - acc: 0.6843 - val_loss: 0.5955 - val_acc: 0.6850\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5945 - acc: 0.6878 - val_loss: 0.5956 - val_acc: 0.6795\n",
      "8000/8000 [==============================] - 1s 124us/step\n",
      "2000/2000 [==============================] - 0s 125us/step\n",
      "2000/2000 [==============================] - 0s 129us/step\n",
      "\n",
      "Iteration 9\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 1s 177ms/step - loss: 0.6588 - acc: 0.5948 - val_loss: 0.6420 - val_acc: 0.6505\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6329 - acc: 0.6614 - val_loss: 0.6222 - val_acc: 0.6605\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6169 - acc: 0.6642 - val_loss: 0.6147 - val_acc: 0.6670\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 41ms/step - loss: 0.6093 - acc: 0.6674 - val_loss: 0.6077 - val_acc: 0.6670\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.6042 - acc: 0.6788 - val_loss: 0.6072 - val_acc: 0.6620\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.6021 - acc: 0.6731 - val_loss: 0.6055 - val_acc: 0.6780\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 40ms/step - loss: 0.5983 - acc: 0.6799 - val_loss: 0.6033 - val_acc: 0.6750\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 34ms/step - loss: 0.5967 - acc: 0.6858 - val_loss: 0.6039 - val_acc: 0.6825\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5960 - acc: 0.6849 - val_loss: 0.6018 - val_acc: 0.6755\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 38ms/step - loss: 0.5938 - acc: 0.6916 - val_loss: 0.6013 - val_acc: 0.6750\n",
      "8000/8000 [==============================] - 0s 59us/step\n",
      "2000/2000 [==============================] - 0s 60us/step\n",
      "2000/2000 [==============================] - 0s 61us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 64)        16448     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1000)              12545000  \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 13,063,270\n",
      "Trainable params: 13,063,270\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.942$\\pm$0.004\n"
     ]
    }
   ],
   "source": [
    "Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar = loaddata()\n",
    "\n",
    "Xtr_mnist,Xts_mnist = standard(Xtr_mnist,Xts_mnist)\n",
    "\n",
    "\n",
    "result = cnn_loss_correct(Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist,iteration=10,lr=0.00005, decay=0.0000001, \n",
    "                     batchsize=1024,epochs=10,TYPE='mnist',loss_name = 'forward')\n",
    "\n",
    "# Print the test accuracy\n",
    "print('{}$\\pm${}'.format(round(result[4],3),round(result[5],3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 232ms/step - loss: 0.6792 - acc: 0.5760 - val_loss: 0.6533 - val_acc: 0.6205\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.6427 - acc: 0.6343 - val_loss: 0.6328 - val_acc: 0.6410\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6272 - acc: 0.6480 - val_loss: 0.6284 - val_acc: 0.6480\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6182 - acc: 0.6655 - val_loss: 0.6243 - val_acc: 0.6625\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6107 - acc: 0.6752 - val_loss: 0.6235 - val_acc: 0.6570\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6014 - acc: 0.6848 - val_loss: 0.6203 - val_acc: 0.6595\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5931 - acc: 0.6980 - val_loss: 0.6226 - val_acc: 0.6610\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5839 - acc: 0.7034 - val_loss: 0.6189 - val_acc: 0.6625\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5734 - acc: 0.7184 - val_loss: 0.6186 - val_acc: 0.6685\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5633 - acc: 0.7245 - val_loss: 0.6208 - val_acc: 0.6690\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 210ms/step - loss: 0.6731 - acc: 0.5960 - val_loss: 0.6480 - val_acc: 0.6115\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6419 - acc: 0.6367 - val_loss: 0.6333 - val_acc: 0.6350\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6272 - acc: 0.6517 - val_loss: 0.6275 - val_acc: 0.6385\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6162 - acc: 0.6723 - val_loss: 0.6290 - val_acc: 0.6350\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6099 - acc: 0.6776 - val_loss: 0.6251 - val_acc: 0.6420\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5984 - acc: 0.6898 - val_loss: 0.6228 - val_acc: 0.6570\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5883 - acc: 0.7018 - val_loss: 0.6238 - val_acc: 0.6590\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5809 - acc: 0.7073 - val_loss: 0.6358 - val_acc: 0.6490\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5704 - acc: 0.7221 - val_loss: 0.6224 - val_acc: 0.6520\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5584 - acc: 0.7334 - val_loss: 0.6235 - val_acc: 0.6660\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 212ms/step - loss: 0.6599 - acc: 0.6114 - val_loss: 0.6292 - val_acc: 0.6580\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6267 - acc: 0.6535 - val_loss: 0.6160 - val_acc: 0.6615\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6135 - acc: 0.6685 - val_loss: 0.6193 - val_acc: 0.6675\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6064 - acc: 0.6818 - val_loss: 0.6155 - val_acc: 0.6630\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5937 - acc: 0.6879 - val_loss: 0.6164 - val_acc: 0.6505\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5823 - acc: 0.7029 - val_loss: 0.6170 - val_acc: 0.6690\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5709 - acc: 0.7186 - val_loss: 0.6315 - val_acc: 0.6350\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5643 - acc: 0.7123 - val_loss: 0.6156 - val_acc: 0.6660\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5464 - acc: 0.7390 - val_loss: 0.6165 - val_acc: 0.6550\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5332 - acc: 0.7544 - val_loss: 0.6224 - val_acc: 0.6525\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 217ms/step - loss: 0.6858 - acc: 0.5700 - val_loss: 0.6374 - val_acc: 0.6400\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6401 - acc: 0.6238 - val_loss: 0.6298 - val_acc: 0.6555\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 52ms/step - loss: 0.6265 - acc: 0.6530 - val_loss: 0.6276 - val_acc: 0.6535\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6192 - acc: 0.6572 - val_loss: 0.6259 - val_acc: 0.6515\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6104 - acc: 0.6697 - val_loss: 0.6330 - val_acc: 0.6410\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6032 - acc: 0.6789 - val_loss: 0.6265 - val_acc: 0.6560\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5940 - acc: 0.6894 - val_loss: 0.6337 - val_acc: 0.6470\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5873 - acc: 0.6953 - val_loss: 0.6241 - val_acc: 0.6580\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5741 - acc: 0.7122 - val_loss: 0.6210 - val_acc: 0.6575\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.5643 - acc: 0.7220 - val_loss: 0.6343 - val_acc: 0.6410\n",
      "\n",
      "Iteration 4\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 234ms/step - loss: 0.6657 - acc: 0.5961 - val_loss: 0.6318 - val_acc: 0.6175\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6379 - acc: 0.6335 - val_loss: 0.6175 - val_acc: 0.6440\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6225 - acc: 0.6560 - val_loss: 0.6169 - val_acc: 0.6630\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 53ms/step - loss: 0.6149 - acc: 0.6679 - val_loss: 0.6195 - val_acc: 0.6595\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6051 - acc: 0.6838 - val_loss: 0.6144 - val_acc: 0.6610\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5932 - acc: 0.6967 - val_loss: 0.6128 - val_acc: 0.6555\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5836 - acc: 0.7054 - val_loss: 0.6115 - val_acc: 0.6600\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5756 - acc: 0.7143 - val_loss: 0.6381 - val_acc: 0.6550\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 55ms/step - loss: 0.5729 - acc: 0.7107 - val_loss: 0.6268 - val_acc: 0.6435\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5661 - acc: 0.7128 - val_loss: 0.6170 - val_acc: 0.6600\n",
      "\n",
      "Iteration 5\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 223ms/step - loss: 0.6816 - acc: 0.5838 - val_loss: 0.6582 - val_acc: 0.5980\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6433 - acc: 0.6315 - val_loss: 0.6496 - val_acc: 0.6055\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6258 - acc: 0.6512 - val_loss: 0.6629 - val_acc: 0.5885\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6173 - acc: 0.6637 - val_loss: 0.6458 - val_acc: 0.6210\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6082 - acc: 0.6777 - val_loss: 0.6453 - val_acc: 0.6200\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6022 - acc: 0.6837 - val_loss: 0.6444 - val_acc: 0.6275\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5948 - acc: 0.6862 - val_loss: 0.6413 - val_acc: 0.6340\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5847 - acc: 0.7032 - val_loss: 0.6380 - val_acc: 0.6320\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5759 - acc: 0.7126 - val_loss: 0.6447 - val_acc: 0.6210\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5698 - acc: 0.7080 - val_loss: 0.6440 - val_acc: 0.6165\n",
      "\n",
      "Iteration 6\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 232ms/step - loss: 0.6774 - acc: 0.5747 - val_loss: 0.6493 - val_acc: 0.6025\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6427 - acc: 0.6283 - val_loss: 0.6311 - val_acc: 0.6650\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6273 - acc: 0.6512 - val_loss: 0.6293 - val_acc: 0.6635\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 54ms/step - loss: 0.6199 - acc: 0.6638 - val_loss: 0.6240 - val_acc: 0.6630\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6101 - acc: 0.6776 - val_loss: 0.6219 - val_acc: 0.6700\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6037 - acc: 0.6795 - val_loss: 0.6223 - val_acc: 0.6670\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5953 - acc: 0.6903 - val_loss: 0.6212 - val_acc: 0.6660\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5863 - acc: 0.6998 - val_loss: 0.6208 - val_acc: 0.6660\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 53ms/step - loss: 0.5769 - acc: 0.7111 - val_loss: 0.6211 - val_acc: 0.6665\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5668 - acc: 0.7199 - val_loss: 0.6285 - val_acc: 0.6595\n",
      "\n",
      "Iteration 7\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 231ms/step - loss: 0.6845 - acc: 0.5666 - val_loss: 0.6546 - val_acc: 0.6175\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6403 - acc: 0.6362 - val_loss: 0.6371 - val_acc: 0.6385\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6257 - acc: 0.6582 - val_loss: 0.6371 - val_acc: 0.6410\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6178 - acc: 0.6670 - val_loss: 0.6342 - val_acc: 0.6390\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6086 - acc: 0.6795 - val_loss: 0.6344 - val_acc: 0.6345\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6035 - acc: 0.6767 - val_loss: 0.6368 - val_acc: 0.6340\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 54ms/step - loss: 0.5948 - acc: 0.6901 - val_loss: 0.6391 - val_acc: 0.6280\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5855 - acc: 0.6993 - val_loss: 0.6309 - val_acc: 0.6455\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5760 - acc: 0.7127 - val_loss: 0.6407 - val_acc: 0.6530\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5688 - acc: 0.7207 - val_loss: 0.6350 - val_acc: 0.6365\n",
      "\n",
      "Iteration 8\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 256ms/step - loss: 0.6901 - acc: 0.5680 - val_loss: 0.6621 - val_acc: 0.5930\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6493 - acc: 0.6150 - val_loss: 0.6498 - val_acc: 0.6245\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6367 - acc: 0.6388 - val_loss: 0.6517 - val_acc: 0.6200\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6261 - acc: 0.6600 - val_loss: 0.6377 - val_acc: 0.6480\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6172 - acc: 0.6687 - val_loss: 0.6321 - val_acc: 0.6465\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6085 - acc: 0.6778 - val_loss: 0.6331 - val_acc: 0.6485\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6016 - acc: 0.6836 - val_loss: 0.6311 - val_acc: 0.6475\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5926 - acc: 0.6958 - val_loss: 0.6293 - val_acc: 0.6580\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5861 - acc: 0.7030 - val_loss: 0.6288 - val_acc: 0.6525\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5730 - acc: 0.7172 - val_loss: 0.6329 - val_acc: 0.6585\n",
      "\n",
      "Iteration 9\n",
      "\n",
      "\n",
      "Train model with noise \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 247ms/step - loss: 0.6585 - acc: 0.6059 - val_loss: 0.6470 - val_acc: 0.6175\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6414 - acc: 0.6398 - val_loss: 0.6419 - val_acc: 0.6490\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6276 - acc: 0.6523 - val_loss: 0.6277 - val_acc: 0.6490\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6185 - acc: 0.6604 - val_loss: 0.6317 - val_acc: 0.6500\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6121 - acc: 0.6712 - val_loss: 0.6230 - val_acc: 0.6525\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5999 - acc: 0.6877 - val_loss: 0.6225 - val_acc: 0.6500\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5898 - acc: 0.6994 - val_loss: 0.6253 - val_acc: 0.6505\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5810 - acc: 0.7032 - val_loss: 0.6226 - val_acc: 0.6570\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5727 - acc: 0.7157 - val_loss: 0.6241 - val_acc: 0.6550\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5638 - acc: 0.7253 - val_loss: 0.6243 - val_acc: 0.6605\n",
      "[[0.82473534 0.17526466]\n",
      " [0.35665483 0.64334516]]  \n",
      " \n",
      "  [[0.02716543 0.02716545]\n",
      " [0.05067201 0.05067202]]\n"
     ]
    }
   ],
   "source": [
    "Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar = loaddata()\n",
    "\n",
    "Xtr_cifar,Xts_cifar = standard(Xtr_cifar,Xts_cifar)\n",
    "\n",
    "result = cnn_loss_correct_compute_T(Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar,iteration=10,lr=0.00005, decay=0.0000001, \n",
    "                     batchsize=1024,epochs=10,TYPE='cifar',loss_name = 'forward')\n",
    "\n",
    "# Print the average T and std\n",
    "print('{}  \\n \\n  {}'.format(result[0],result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use given T to train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 245ms/step - loss: 0.6599 - acc: 0.5438 - val_loss: 0.6415 - val_acc: 0.5770\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6358 - acc: 0.6088 - val_loss: 0.6284 - val_acc: 0.6340\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6255 - acc: 0.6286 - val_loss: 0.6241 - val_acc: 0.6340\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6193 - acc: 0.6400 - val_loss: 0.6228 - val_acc: 0.6490\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6157 - acc: 0.6496 - val_loss: 0.6205 - val_acc: 0.6425\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6099 - acc: 0.6570 - val_loss: 0.6189 - val_acc: 0.6475\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 53ms/step - loss: 0.6058 - acc: 0.6665 - val_loss: 0.6179 - val_acc: 0.6500\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6009 - acc: 0.6763 - val_loss: 0.6170 - val_acc: 0.6530\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5997 - acc: 0.6783 - val_loss: 0.6187 - val_acc: 0.6445\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5954 - acc: 0.6838 - val_loss: 0.6245 - val_acc: 0.6570\n",
      "8000/8000 [==============================] - 1s 115us/step\n",
      "2000/2000 [==============================] - 0s 126us/step\n",
      "2000/2000 [==============================] - 0s 176us/step\n",
      "\n",
      "Iteration 1\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 254ms/step - loss: 0.6494 - acc: 0.5624 - val_loss: 0.6462 - val_acc: 0.6020\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6292 - acc: 0.6195 - val_loss: 0.6371 - val_acc: 0.6480\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6226 - acc: 0.6336 - val_loss: 0.6400 - val_acc: 0.6625\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6171 - acc: 0.6498 - val_loss: 0.6287 - val_acc: 0.6485\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6107 - acc: 0.6559 - val_loss: 0.6269 - val_acc: 0.6380\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6069 - acc: 0.6627 - val_loss: 0.6263 - val_acc: 0.6475\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6028 - acc: 0.6709 - val_loss: 0.6285 - val_acc: 0.6570\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5981 - acc: 0.6811 - val_loss: 0.6248 - val_acc: 0.6485\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5935 - acc: 0.6827 - val_loss: 0.6253 - val_acc: 0.6550\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5875 - acc: 0.7009 - val_loss: 0.6309 - val_acc: 0.6615\n",
      "8000/8000 [==============================] - 1s 89us/step\n",
      "2000/2000 [==============================] - 0s 96us/step\n",
      "2000/2000 [==============================] - 0s 169us/step\n",
      "\n",
      "Iteration 2\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 257ms/step - loss: 0.6530 - acc: 0.5562 - val_loss: 0.6333 - val_acc: 0.6160\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6346 - acc: 0.6087 - val_loss: 0.6263 - val_acc: 0.6365\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6258 - acc: 0.6318 - val_loss: 0.6304 - val_acc: 0.6485\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6216 - acc: 0.6399 - val_loss: 0.6207 - val_acc: 0.6545\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6158 - acc: 0.6446 - val_loss: 0.6173 - val_acc: 0.6570\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6118 - acc: 0.6573 - val_loss: 0.6149 - val_acc: 0.6635\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6082 - acc: 0.6632 - val_loss: 0.6155 - val_acc: 0.6555\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6048 - acc: 0.6735 - val_loss: 0.6119 - val_acc: 0.6590\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6021 - acc: 0.6719 - val_loss: 0.6131 - val_acc: 0.6545\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.5958 - acc: 0.6849 - val_loss: 0.6155 - val_acc: 0.6640\n",
      "8000/8000 [==============================] - 1s 68us/step\n",
      "2000/2000 [==============================] - 0s 78us/step\n",
      "2000/2000 [==============================] - 0s 115us/step\n",
      "\n",
      "Iteration 3\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 264ms/step - loss: 0.6542 - acc: 0.5660 - val_loss: 0.6333 - val_acc: 0.6065\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6330 - acc: 0.6173 - val_loss: 0.6325 - val_acc: 0.5785\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6272 - acc: 0.6312 - val_loss: 0.6264 - val_acc: 0.6090\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 54ms/step - loss: 0.6217 - acc: 0.6354 - val_loss: 0.6221 - val_acc: 0.6275\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6157 - acc: 0.6450 - val_loss: 0.6210 - val_acc: 0.6355\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.6106 - acc: 0.6583 - val_loss: 0.6232 - val_acc: 0.6510\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6066 - acc: 0.6638 - val_loss: 0.6254 - val_acc: 0.6570\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6047 - acc: 0.6750 - val_loss: 0.6185 - val_acc: 0.6410\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6008 - acc: 0.6759 - val_loss: 0.6230 - val_acc: 0.6160\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 52ms/step - loss: 0.6004 - acc: 0.6737 - val_loss: 0.6188 - val_acc: 0.6300\n",
      "8000/8000 [==============================] - 1s 77us/step\n",
      "2000/2000 [==============================] - 0s 79us/step\n",
      "2000/2000 [==============================] - 0s 123us/step\n",
      "\n",
      "Iteration 4\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 295ms/step - loss: 0.6529 - acc: 0.5576 - val_loss: 0.6330 - val_acc: 0.6225\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6343 - acc: 0.6203 - val_loss: 0.6260 - val_acc: 0.6100\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6276 - acc: 0.6263 - val_loss: 0.6212 - val_acc: 0.6310\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6219 - acc: 0.6386 - val_loss: 0.6196 - val_acc: 0.6375\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 53ms/step - loss: 0.6157 - acc: 0.6483 - val_loss: 0.6182 - val_acc: 0.6335\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6132 - acc: 0.6591 - val_loss: 0.6217 - val_acc: 0.6080\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6122 - acc: 0.6541 - val_loss: 0.6161 - val_acc: 0.6420\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6052 - acc: 0.6687 - val_loss: 0.6161 - val_acc: 0.6455\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6023 - acc: 0.6690 - val_loss: 0.6159 - val_acc: 0.6430\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5962 - acc: 0.6854 - val_loss: 0.6153 - val_acc: 0.6580\n",
      "8000/8000 [==============================] - 1s 70us/step\n",
      "2000/2000 [==============================] - 0s 68us/step\n",
      "2000/2000 [==============================] - 0s 96us/step\n",
      "\n",
      "Iteration 5\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 278ms/step - loss: 0.6493 - acc: 0.5720 - val_loss: 0.6369 - val_acc: 0.6050\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6302 - acc: 0.6150 - val_loss: 0.6327 - val_acc: 0.6270\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6233 - acc: 0.6362 - val_loss: 0.6303 - val_acc: 0.6400\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 54ms/step - loss: 0.6179 - acc: 0.6446 - val_loss: 0.6272 - val_acc: 0.6315\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6129 - acc: 0.6564 - val_loss: 0.6245 - val_acc: 0.6310\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 51ms/step - loss: 0.6095 - acc: 0.6601 - val_loss: 0.6236 - val_acc: 0.6360\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.6082 - acc: 0.6577 - val_loss: 0.6236 - val_acc: 0.6425\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6020 - acc: 0.6787 - val_loss: 0.6250 - val_acc: 0.6430\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5965 - acc: 0.6854 - val_loss: 0.6218 - val_acc: 0.6425\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5928 - acc: 0.6894 - val_loss: 0.6284 - val_acc: 0.6530\n",
      "8000/8000 [==============================] - 1s 156us/step\n",
      "2000/2000 [==============================] - 0s 70us/step\n",
      "2000/2000 [==============================] - 0s 100us/step\n",
      "\n",
      "Iteration 6\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 280ms/step - loss: 0.6564 - acc: 0.5492 - val_loss: 0.6400 - val_acc: 0.6055\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6337 - acc: 0.6165 - val_loss: 0.6278 - val_acc: 0.6315\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6256 - acc: 0.6333 - val_loss: 0.6260 - val_acc: 0.6570\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6202 - acc: 0.6430 - val_loss: 0.6212 - val_acc: 0.6460\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6148 - acc: 0.6493 - val_loss: 0.6197 - val_acc: 0.6470\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6101 - acc: 0.6614 - val_loss: 0.6183 - val_acc: 0.6450\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6058 - acc: 0.6692 - val_loss: 0.6167 - val_acc: 0.6455\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6015 - acc: 0.6731 - val_loss: 0.6165 - val_acc: 0.6485\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5955 - acc: 0.6874 - val_loss: 0.6168 - val_acc: 0.6615\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5919 - acc: 0.6917 - val_loss: 0.6157 - val_acc: 0.6395\n",
      "8000/8000 [==============================] - 1s 94us/step\n",
      "2000/2000 [==============================] - 0s 101us/step\n",
      "2000/2000 [==============================] - 0s 114us/step\n",
      "\n",
      "Iteration 7\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 282ms/step - loss: 0.6527 - acc: 0.5567 - val_loss: 0.6336 - val_acc: 0.5895\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.6338 - acc: 0.6152 - val_loss: 0.6206 - val_acc: 0.6345\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6251 - acc: 0.6336 - val_loss: 0.6170 - val_acc: 0.6430\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 55ms/step - loss: 0.6185 - acc: 0.6431 - val_loss: 0.6160 - val_acc: 0.6550\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6142 - acc: 0.6530 - val_loss: 0.6146 - val_acc: 0.6490\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6092 - acc: 0.6658 - val_loss: 0.6151 - val_acc: 0.6285\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6058 - acc: 0.6652 - val_loss: 0.6127 - val_acc: 0.6480\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5998 - acc: 0.6816 - val_loss: 0.6156 - val_acc: 0.6625\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5975 - acc: 0.6903 - val_loss: 0.6141 - val_acc: 0.6275\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 54ms/step - loss: 0.5929 - acc: 0.6897 - val_loss: 0.6137 - val_acc: 0.6325\n",
      "8000/8000 [==============================] - 1s 160us/step\n",
      "2000/2000 [==============================] - 0s 169us/step\n",
      "2000/2000 [==============================] - 0s 103us/step\n",
      "\n",
      "Iteration 8\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 287ms/step - loss: 0.6560 - acc: 0.5452 - val_loss: 0.6349 - val_acc: 0.6490\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6349 - acc: 0.6148 - val_loss: 0.6288 - val_acc: 0.6675\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6279 - acc: 0.6268 - val_loss: 0.6216 - val_acc: 0.6705\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6201 - acc: 0.6438 - val_loss: 0.6167 - val_acc: 0.6585\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 48ms/step - loss: 0.6157 - acc: 0.6524 - val_loss: 0.6141 - val_acc: 0.6585\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6127 - acc: 0.6538 - val_loss: 0.6117 - val_acc: 0.6580\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6088 - acc: 0.6536 - val_loss: 0.6140 - val_acc: 0.6700\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.6038 - acc: 0.6696 - val_loss: 0.6117 - val_acc: 0.6650\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 49ms/step - loss: 0.5995 - acc: 0.6810 - val_loss: 0.6112 - val_acc: 0.6690\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.5941 - acc: 0.6888 - val_loss: 0.6114 - val_acc: 0.6650\n",
      "8000/8000 [==============================] - 1s 76us/step\n",
      "2000/2000 [==============================] - 0s 122us/step\n",
      "2000/2000 [==============================] - 0s 133us/step\n",
      "\n",
      "Iteration 9\n",
      "\n",
      "\n",
      "Train model with loss orrection \n",
      "\n",
      "Epoch 1/10\n",
      "8/7 [==============================] - 2s 288ms/step - loss: 0.6501 - acc: 0.5802 - val_loss: 0.6466 - val_acc: 0.5800\n",
      "Epoch 2/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6301 - acc: 0.6200 - val_loss: 0.6393 - val_acc: 0.6015\n",
      "Epoch 3/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6232 - acc: 0.6301 - val_loss: 0.6366 - val_acc: 0.6000\n",
      "Epoch 4/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6199 - acc: 0.6393 - val_loss: 0.6338 - val_acc: 0.6050\n",
      "Epoch 5/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.6133 - acc: 0.6497 - val_loss: 0.6325 - val_acc: 0.6370\n",
      "Epoch 6/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.6071 - acc: 0.6639 - val_loss: 0.6327 - val_acc: 0.6380\n",
      "Epoch 7/10\n",
      "8/7 [==============================] - 0s 50ms/step - loss: 0.6030 - acc: 0.6675 - val_loss: 0.6301 - val_acc: 0.6320\n",
      "Epoch 8/10\n",
      "8/7 [==============================] - 0s 46ms/step - loss: 0.5984 - acc: 0.6782 - val_loss: 0.6331 - val_acc: 0.6390\n",
      "Epoch 9/10\n",
      "8/7 [==============================] - 0s 45ms/step - loss: 0.5952 - acc: 0.6849 - val_loss: 0.6358 - val_acc: 0.6580\n",
      "Epoch 10/10\n",
      "8/7 [==============================] - 0s 47ms/step - loss: 0.5912 - acc: 0.6971 - val_loss: 0.6312 - val_acc: 0.6440\n",
      "8000/8000 [==============================] - 1s 114us/step\n",
      "2000/2000 [==============================] - 0s 124us/step\n",
      "2000/2000 [==============================] - 0s 134us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 32, 32, 64)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 16, 16, 64)        16448     \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1000)              16385000  \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 16,903,782\n",
      "Trainable params: 16,903,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0.865$\\pm$0.021\n"
     ]
    }
   ],
   "source": [
    "Xtr_mnist, Str_mnist, Xts_mnist, Yts_mnist, Xtr_cifar, Str_cifar, Xts_cifar, Yts_cifar = loaddata()\n",
    "\n",
    "Xtr_cifar,Xts_cifar = standard(Xtr_cifar,Xts_cifar)\n",
    "\n",
    "result = cnn_loss_correct(Xtr_cifar,Str_cifar,Xts_cifar,Yts_cifar,iteration=10,lr=0.00005, decay=0.0000001, \n",
    "                     batchsize=1024,epochs=10,TYPE='cifar',loss_name = 'forward')\n",
    "\n",
    "# Print the test accuracy\n",
    "print('{}$\\pm${}'.format(round(result[4],3),round(result[5],3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
